{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "class NaiveBayesProb:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.raw_data = False\n",
    "        pass\n",
    "    \n",
    "    def read_raw_data(self):\n",
    "        self.target_domain = set()\n",
    "        self.attribute_domains = defaultdict(set)\n",
    "        self.raw_x = []\n",
    "        self.raw_y = []\n",
    "        with open(\"/Users/rbekbolatov/data/uci/mushroom/agaricus-lepiota.data\", \"r\") as datafile:\n",
    "            for line in datafile:\n",
    "                els = line.rstrip('\\n').split(',')\n",
    "                self.raw_y.append(els[0])\n",
    "                self.raw_x.append(els[1:])\n",
    "        self.raw_data = True\n",
    "        \n",
    "    def train_and_evaluate(self, test_fraction=0.2): \n",
    "        self.xs_log_prob_cache = {}\n",
    "        self.train(test_fraction)\n",
    "        return self.evaluate()\n",
    "        \n",
    "    def train(self, test_fraction=0.2): \n",
    "        if not self.raw_data:\n",
    "            self.read_raw_data()\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.raw_x, self.raw_y, test_size=test_fraction, random_state=42)\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.n_train = len(self.y_train)\n",
    "        self.n_test = len(self.y_test)\n",
    "        self.count()\n",
    "        \n",
    "    def count(self):\n",
    "        self.counts = Counter()\n",
    "        self.y_counts = Counter()\n",
    "        for (y, xs) in zip(self.y_train, self.x_train):\n",
    "            self.y_counts[y] += 1\n",
    "            self.target_domain.add(y)\n",
    "            for (i, x) in enumerate(xs):\n",
    "                self.counts[(i, y, x)] += 1\n",
    "                self.attribute_domains[i].add(x)\n",
    "                \n",
    "    def y_prior_log_prob(self, y):\n",
    "        return math.log(self.y_counts[y] * 1.0 / self.n_train)\n",
    "    \n",
    "    def x_i_class_cond_log_prob(self, idx, x, given_y, lap=1.0):\n",
    "        return math.log((self.counts[(idx, given_y, x)] + lap) * 1.0 / (self.y_counts[given_y] + lap*len(self.attribute_domains[idx])))\n",
    "    \n",
    "    def xs_class_cond_log_prob(self, xs, given_y):\n",
    "        # Naive Bayes assumption p((x1,..., xk)|y)=p(x1|y)*p(x2|y)*...*p(xk|y)\n",
    "        return self.xs_class_cond_NB_log_prob(xs, given_y)\n",
    "\n",
    "    def xs_class_cond_NB_log_prob(self, xs, given_y):\n",
    "        return sum([self.x_i_class_cond_log_prob(i, xs[i], given_y) for i in range(len(self.attribute_domains))])\n",
    "\n",
    "    def xs_y_joint_log_prob(self, xs, y):\n",
    "        return self.y_prior_log_prob(y) + self.xs_class_cond_log_prob(xs, y)\n",
    "\n",
    "    def xs_log_prob(self, xs):\n",
    "        cached = self.xs_log_prob_cache.get(tuple(xs))\n",
    "        if cached is None:\n",
    "            cached = math.log(sum([math.exp(self.xs_y_joint_log_prob(xs, y)) for y in self.target_domain]))\n",
    "            self.xs_log_prob_cache[tuple(xs)] = cached\n",
    "        return cached\n",
    "\n",
    "    # NBC, After Bayes\n",
    "    def y_posterior_log_prob_NBC(self, y, given_xs):\n",
    "        return self.xs_y_joint_log_prob(given_xs, y) - self.xs_log_prob(given_xs)\n",
    "    \n",
    "    def y_posterior_prob_NBC(self, y, given_xs):\n",
    "        return math.exp(self.y_posterior_log_prob_NBC(y, given_xs))\n",
    "    \n",
    "    def y_posterior_prob_dist_NBC(self, given_xs):\n",
    "        return {y: self.y_posterior_prob_NBC(y, given_xs) for y in self.target_domain}\n",
    "    \n",
    "    def y_predict_NBC(self, given_xs):\n",
    "        max_log_prob = None\n",
    "        max_log_prob_target = None\n",
    "        for y in self.target_domain:\n",
    "            prob = self.y_posterior_log_prob_NBC(y, given_xs)\n",
    "            if max_log_prob is None or max_log_prob < prob:\n",
    "                max_log_prob = prob\n",
    "                max_log_prob_target = y\n",
    "        return (max_log_prob_target, math.exp(max_log_prob))\n",
    "    \n",
    "    # Evaluate against test set:\n",
    "    def test_accuracy_NBC(self):\n",
    "        return sum([1 if self.y_predict_NBC(xs)[0] == y else 0 for (xs, y) in zip(self.x_test, self.y_test)]) * 1.0 / self.n_test\n",
    "    \n",
    "    def test_accuracy_LOGREG(self):\n",
    "        # placeholder\n",
    "        return self.test_accuracy_NBC()\n",
    "    \n",
    "    \n",
    "    def evaluate(self):\n",
    "        baseline_accuracy = 1.0 - math.exp(max([self.y_prior_log_prob(y) for y in self.target_domain]))\n",
    "        nbc_accuracy = self.test_accuracy_NBC()\n",
    "        logreg_accuracy = self.test_accuracy_LOGREG()\n",
    "        print('Baseline accuracy: ' + str(baseline_accuracy))\n",
    "        print('Naive Bayes classifier accuracy: ' + str(nbc_accuracy))\n",
    "        print('Logistic Regression classifier accuracy: ' + str(logreg_accuracy))\n",
    "        return (baseline_accuracy, nbc_accuracy, logreg_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "Baseline accuracy: 0.479064039409\n",
      "Naive Bayes classifier accuracy: 0.941384615385\n",
      "Logistic Regression classifier accuracy: 0.941384615385\n",
      "CPU times: user 1.02 s, sys: 5.58 ms, total: 1.03 s\n",
      "Wall time: 1.03 s\n",
      "0.5\n",
      "Baseline accuracy: 0.477351058592\n",
      "Naive Bayes classifier accuracy: 0.946085672083\n",
      "Logistic Regression classifier accuracy: 0.946085672083\n",
      "CPU times: user 696 ms, sys: 3.33 ms, total: 700 ms\n",
      "Wall time: 702 ms\n",
      "0.4\n",
      "Baseline accuracy: 0.480919162905\n",
      "Naive Bayes classifier accuracy: 0.947076923077\n",
      "Logistic Regression classifier accuracy: 0.947076923077\n",
      "CPU times: user 584 ms, sys: 1.94 ms, total: 586 ms\n",
      "Wall time: 587 ms\n",
      "0.3\n",
      "Baseline accuracy: 0.481005979599\n",
      "Naive Bayes classifier accuracy: 0.945857260049\n",
      "Logistic Regression classifier accuracy: 0.945857260049\n",
      "CPU times: user 467 ms, sys: 1.21 ms, total: 469 ms\n",
      "Wall time: 469 ms\n",
      "0.2\n",
      "Baseline accuracy: 0.482228035082\n",
      "Naive Bayes classifier accuracy: 0.950769230769\n",
      "Logistic Regression classifier accuracy: 0.950769230769\n",
      "CPU times: user 371 ms, sys: 810 µs, total: 371 ms\n",
      "Wall time: 372 ms\n",
      "0.1\n",
      "Baseline accuracy: 0.48365476679\n",
      "Naive Bayes classifier accuracy: 0.956949569496\n",
      "Logistic Regression classifier accuracy: 0.956949569496\n",
      "CPU times: user 248 ms, sys: 873 µs, total: 249 ms\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [0.8, 0.5, 0.4, 0.3, 0.2, 0.1]:\n",
    "    print(i)\n",
    "    %time NaiveBayesProb().train_and_evaluate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
