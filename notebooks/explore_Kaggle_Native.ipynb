{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import re\n",
    "\n",
    "data_loc = '/Users/rbekbolatov/data/kaggle/native/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs = {}\n",
    "\n",
    "for i in range(5):\n",
    "    files = pd.read_csv(data_loc + 'files_in/files_in_' + str(i), header=None, names=['filename'])\n",
    "    files['dir'] = i\n",
    "    dirs[i] = set(files['filename'])\n",
    "    \n",
    "def get_dir(filename):\n",
    "    for i in range(5):\n",
    "        if filename in dirs[i]:\n",
    "            return i\n",
    "    return -1  \n",
    "\n",
    "eval_labels = pd.read_csv(data_loc + 'train.csv')\n",
    "eval_labels_sample = eval_labels.sample(N)\n",
    "\n",
    "train, test = train_test_split(eval_labels_sample, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sponsored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87670</th>\n",
       "      <td>3284006_raw_html.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  sponsored\n",
       "87670  3284006_raw_html.txt          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_labels[eval_labels['file'] == '3284006_raw_html.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_files = pd.read_csv(data_loc + 'all_filenames.csv', header=None, names=['file', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_subsamples(all_files):\n",
    "    files_8k = all_files.sample(8000, random_state = 101)\n",
    "    files_3k = all_files.sample(3000, random_state = 101)\n",
    "    files_100 = all_files.sample(100, random_state = 101)\n",
    "    # save files\n",
    "    subsamples_loc = data_loc + 'subsamples/'\n",
    "    files_8k['file'].to_csv(subsamples_loc + 'files8k.csv', index=False)\n",
    "    files_3k['file'].to_csv(subsamples_loc + 'files3k.csv', index=False)\n",
    "    files_100['file'].to_csv(subsamples_loc + 'files100.csv', index=False)\n",
    "    # have filenames here\n",
    "    files_8k = np.asarray(files_8k['file'])\n",
    "    files_3k = np.asarray(files_3k['file'])\n",
    "    files_100 = np.asarray(files_100['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_soup(filename):\n",
    "    file_handle = open(data_loc + str(get_dir(filename)) + '/' + filename)\n",
    "    file_content = file_handle.read()\n",
    "    file_handle.close()\n",
    "    soup = bs(file_content)\n",
    "    return soup\n",
    "\n",
    "def get_paragraphs(soup):\n",
    "    paragraphs = soup.findAll('p')\n",
    "    cleaned_texts = [re.sub(r'[\\'\"|\\n\\t,.:;()\\-\\/]+', ' ', p.text.encode('ascii', 'ignore').strip()) for p in paragraphs]\n",
    "    return cleaned_texts \n",
    "\n",
    "def get_title(soup):\n",
    "    title = soup.find('title')\n",
    "    title = '' if not title else title.text\n",
    "    title = 'long_title' if len(title) > 200 else title.encode('ascii', 'ignore').strip().replace('\\n',' ')\n",
    "    return title\n",
    "\n",
    "def get_links(soup):\n",
    "    hrefs = []\n",
    "    texts = []\n",
    "    links = soup.findAll('a')\n",
    "    hrefs = [a.href for a in links]\n",
    "    texts = [re.sub(r'[\\'\"|\\n\\t,.:;()\\-\\/]+', ' ', a.text.encode('ascii', 'ignore').strip()) for a in links]\n",
    "    return hrefs, texts\n",
    "    \n",
    "def get_tag_data(files):\n",
    "    data = []\n",
    "    for filename in files:\n",
    "        with open(data_loc + str(get_dir(filename)) + '/' + filename, 'r') as f:\n",
    "            file_content = f.read()\n",
    "            #print (file_content)\n",
    "            if file_content:\n",
    "                soup = bs(file_content, 'lxml') #, 'html.parser')\n",
    "                title = get_title(soup)\n",
    "                link_hrefs, link_texts = get_links(soup)\n",
    "                data.append((filename, title, len(link_hrefs)))\n",
    "\n",
    "    print 'Data size: %d' % len(data)\n",
    "    data = pd.DataFrame(data, columns = ['file', 'title', 'num_a'])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 99\n",
      "Data size: 100\n"
     ]
    }
   ],
   "source": [
    "data_train = get_tag_data(train['file'])\n",
    "data_test = get_tag_data(test['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train = train.merge(data_train)\n",
    "data_test = test.merge(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bcf37d6e102e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'2463122_raw_html.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "data_train[data_train['file'] == '2463122_raw_html.txt'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>title</th>\n",
       "      <th>num_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2518326_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Dont Let Back Pain Ruin Your Holiday: Our Oste...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2419354_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Full Exposure | Smashbox Cosmetics</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1898596_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Writing About Writing (And Occasionally Some W...</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1995480_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>World Culture Examiner: Argosy University Onli...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>91339_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Vinulu - Sagging at it's finest</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>474327_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>The Big List of upcoming Indie Sci-Fi Space Ga...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1545265_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>lumenznetworks.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2858373_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>The 6 Best Pen Vaporizers On The Market | Smok...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>942100_raw_html.txt</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  sponsored  \\\n",
       "3   2518326_raw_html.txt          1   \n",
       "18  2419354_raw_html.txt          1   \n",
       "22  1898596_raw_html.txt          1   \n",
       "35  1995480_raw_html.txt          1   \n",
       "40    91339_raw_html.txt          1   \n",
       "60   474327_raw_html.txt          1   \n",
       "61  1545265_raw_html.txt          1   \n",
       "79  2858373_raw_html.txt          1   \n",
       "82   942100_raw_html.txt          1   \n",
       "\n",
       "                                                title  num_a  \n",
       "3   Dont Let Back Pain Ruin Your Holiday: Our Oste...     66  \n",
       "18                 Full Exposure | Smashbox Cosmetics    120  \n",
       "22  Writing About Writing (And Occasionally Some W...    351  \n",
       "35  World Culture Examiner: Argosy University Onli...      4  \n",
       "40                    Vinulu - Sagging at it's finest     44  \n",
       "60  The Big List of upcoming Indie Sci-Fi Space Ga...     59  \n",
       "61                                 lumenznetworks.com      1  \n",
       "79  The 6 Best Pen Vaporizers On The Market | Smok...    153  \n",
       "82                                                         1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[data_train['sponsored'] == 1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>title</th>\n",
       "      <th>num_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, sponsored, title, num_a]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[data_train['file'] == '1582003_raw_html.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_labels = pd.read_csv(data_loc + 'train.csv')\n",
    "lb_labels = pd.read_csv(data_loc + 'sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filenames = ['1767762_raw_html.txt', '1542621_raw_html.txt', '625398_raw_html.txt', '1554226_raw_html.txt']\n",
    "filenames = ['625398_raw_html.txt', '1554226_raw_html.txt']\n",
    "soups = [(filename, get_soup(filename)) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = [soup.find('title').text.encode('ascii', 'ignore').strip() for filename, soup in soups]\n",
    "tags = ['a', 'p', 'div', 'script', 'img', 'ul', 'ol', 'hr', 'b', 'i']\n",
    "tag_data = {filename: {tag: soup.findAll(tag) for tag in tags} for filename, soup in soups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('625398_raw_html.txt',\n",
       "  {'a': 20,\n",
       "   'b': 0,\n",
       "   'div': 40,\n",
       "   'hr': 0,\n",
       "   'i': 0,\n",
       "   'img': 14,\n",
       "   'ol': 0,\n",
       "   'p': 40,\n",
       "   'script': 11,\n",
       "   'ul': 2}),\n",
       " ('1554226_raw_html.txt',\n",
       "  {'a': 358,\n",
       "   'b': 5,\n",
       "   'div': 213,\n",
       "   'hr': 0,\n",
       "   'i': 0,\n",
       "   'img': 209,\n",
       "   'ol': 0,\n",
       "   'p': 28,\n",
       "   'script': 95,\n",
       "   'ul': 32})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(filename, {tag: len(file_tags[tag]) for tag in tags}) for filename, file_tags in tag_data.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['',\n",
       "  'We are surrounded by a society which seems to enjoy inflicting us with their scary birth stories ',\n",
       "  '',\n",
       "  'I have created this part of my website to give you a place to read POSITIVE  encouraging  uplifting birth stories  The majority of the stories are of moms using hypnosis  most of them using Hypnobabies during their births  If you enjoy birth stories  sign up for my newsletter  many will include a positive birth story!',\n",
       "  '',\n",
       "  '',\n",
       "  'Proudly powered by WordPress                                              WordPress Theme Custom Community 2                      developed by ThemeKraft'],\n",
       " ['Pregnancy Birth and Babies',\n",
       "  'Welcome',\n",
       "  'Big Baby Bull',\n",
       "  'Hypnosis for Birth',\n",
       "  'What is Hypnosis for Birth?',\n",
       "  'Comparison of Hypnobabies and HypnoBirthing',\n",
       "  'What are my Options?',\n",
       "  'Hypnosis for Pregnancy',\n",
       "  'Epidural or Hypnobabies or Both?',\n",
       "  'Calmer Baby?',\n",
       "  'Birth Videos',\n",
       "  'Positive Birth Stories',\n",
       "  'VBAC Support',\n",
       "  'Essential Oils',\n",
       "  'Free Book',\n",
       "  '',\n",
       "  'www hypnobabies wordpress com',\n",
       "  'Newsletter',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Amazon com Widgets',\n",
       "  '',\n",
       "  '',\n",
       "  'Visit Sheridan Ripley s profile on Pinterest ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'By PoseLab',\n",
       "  'Show more videos',\n",
       "  'Proudly powered by WordPress',\n",
       "  'WordPress Theme Custom Community 2'],\n",
       " [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = get_soup('1542621_raw_html.txt') # '1767762_raw_html.txt')\n",
    "texts = get_paragraphs(soup)\n",
    "ts, rs = get_links(soup)\n",
    "texts,rs,ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
