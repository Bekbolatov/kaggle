{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from gini import normalized_gini, gini_eval\n",
    "from dataset import get_data\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "params = pd.DataFrame({\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": [0.04, 0.03, 0.03, 0.03, 0.02],\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": [1, 0.9, 0.95, 1, 0.6],\n",
    "    \"colsample_bytree\": [0.7, 0.6, 0.65, 0.6, 0.85],\n",
    "    \"max_depth\": [8, 7, 9, 10, 10],\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"scale_pos_weight\": 1,\n",
    "    \"silent\": 0\n",
    "})\n",
    "\n",
    "\n",
    "dat_x_orig, dat_y_orig, lb_x_orig, lb_ind_orig = get_data()\n",
    "dat_x = dat_x_orig\n",
    "dat_y = dat_y_orig\n",
    "lb_x = lb_x_orig\n",
    "lb_ind = lb_x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(dat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (41309, 38), cv1 shape: (4590, 38), cv2 shape: (5100, 38)\n"
     ]
    }
   ],
   "source": [
    "seen_index, cv2_index = train_test_split(range(dat_x_orig.shape[0]), test_size=0.1, random_state=11101)\n",
    "\n",
    "seen_x = dat_x.iloc[seen_index]\n",
    "seen_y = dat_y[seen_index]\n",
    "cv2_x = dat_x.iloc[cv2_index]\n",
    "cv2_y = dat_y[cv2_index]\n",
    "\n",
    "train_index, cv1_index = train_test_split(range(seen_x.shape[0]), test_size=0.1, random_state=11103)\n",
    "\n",
    "train_x = seen_x.iloc[train_index]\n",
    "train_y = seen_y[train_index]\n",
    "cv1_x = seen_x.iloc[cv1_index]\n",
    "cv1_y = seen_y[cv1_index]\n",
    "\n",
    "print(\"train shape: %s, cv1 shape: %s, cv2 shape: %s\"%(str(train_x.shape), str(cv1_x.shape), str(cv2_x.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# DATA FOR XGB\n",
    "xgb_train = xgb.DMatrix(train_x, label=train_y)\n",
    "xgb_cv1 = xgb.DMatrix(cv1_x, label=cv1_y)\n",
    "xgb_cv2 = xgb.DMatrix(cv2_x, label=cv2_y)\n",
    "watchlist = [(xgb_cv2, 'cv2'), (xgb_cv1, 'cv1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(true_y, pred_y, label):\n",
    "    mse = sum(np.power( pred_y - true_y, 2 ))/true_y.shape[0]\n",
    "    gini = normalized_gini(true_y, pred_y)\n",
    "    print(\"%s: Gini=%0.5f, MSE=%0.3f, \"%(label, gini, mse))\n",
    "    return (mse, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv1 error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[129]\tcv2-Gini:0.387476\tcv1-Gini:0.393520\n",
      "\n",
      "Will train until cv1 error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[270]\tcv2-Gini:0.397285\tcv1-Gini:0.397057\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv1 #0: Gini=0.39346, MSE=14.104, \n",
      "cv2 #0: Gini=0.38729, MSE=15.213, \n",
      "cv1 #1: Gini=0.39701, MSE=14.013, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv1 error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[161]\tcv2-Gini:0.388376\tcv1-Gini:0.394748\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cv2 #1: Gini=0.39715, MSE=15.033, \n",
      "cv1 #2: Gini=0.39465, MSE=14.050, \n",
      "cv2 #2: Gini=0.38848, MSE=15.122, \n"
     ]
    }
   ],
   "source": [
    "cv1_blend_x = np.empty_like(cv1_y)\n",
    "cv2_blend_x = np.empty_like(cv2_y)\n",
    "\n",
    "MODELS = 3\n",
    "cv1_errors = np.empty([1, 2])\n",
    "cv2_errors = np.empty([1, 2])\n",
    "\n",
    "for model_number in range(MODELS):\n",
    "    model = xgb.train(params.iloc[model_number].to_dict(), xgb_train, num_boost_round = 3000,\n",
    "                      evals = watchlist,\n",
    "                      feval = gini_eval,\n",
    "                      verbose_eval = False,\n",
    "                      early_stopping_rounds=50)\n",
    "\n",
    "    cv1_y_preds = model.predict(xgb_cv1, ntree_limit=model.best_iteration)\n",
    "    cv2_y_preds = model.predict(xgb_cv2, ntree_limit=model.best_iteration)\n",
    "\n",
    "    cv1_errors = np.vstack((cv1_errors, np.asarray(evaluate(cv1_y, cv1_y_preds, \"cv1 #%d\" % model_number))))\n",
    "    cv2_errors = np.vstack((cv2_errors, np.asarray(evaluate(cv2_y, cv2_y_preds, \"cv2 #%d\" % model_number))))\n",
    "    \n",
    "    cv1_blend_x = np.vstack( (cv1_blend_x, cv1_y_preds))\n",
    "    cv2_blend_x = np.vstack( (cv2_blend_x, cv2_y_preds))\n",
    "    \n",
    "cv1_blend_x = cv1_blend_x[1:].T    \n",
    "cv2_blend_x = cv2_blend_x[1:].T    \n",
    "cv1_errors = cv1_errors[1:].T\n",
    "cv2_errors = cv2_errors[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg cv1: 0.39504 cv2: 0.39097\n",
      "    cv1 with fit to cv1: Gini=0.39771, MSE=13.992, \n",
      "(*) cv2 with fit to cv1: Gini=0.39616, MSE=15.040, \n",
      "    cv1 with fit to cv2: Gini=0.39523, MSE=14.015, \n",
      "    cv2 with fit to cv2: Gini=0.39611, MSE=15.015, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.015372023022781, 0.3961118666666787)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Avg cv1: %0.5f cv2: %0.5f\" %(np.mean(cv1_errors[1]), np.mean(cv2_errors[1])))\n",
    "\n",
    "lr1 = LinearRegression()\n",
    "lr1.fit(cv1_blend_x, cv1_y)\n",
    "cv1_blend_y_1 = lr1.predict(cv1_blend_x)\n",
    "cv2_blend_y_1 = lr1.predict(cv2_blend_x)\n",
    "evaluate(cv1_y, cv1_blend_y_1, \"    cv1 with fit to cv1\")\n",
    "evaluate(cv2_y, cv2_blend_y_1, \"(*) cv2 with fit to cv1\")\n",
    "\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(cv2_blend_x, cv2_y)\n",
    "cv1_blend_y_2 = lr2.predict(cv1_blend_x)\n",
    "cv2_blend_y_2 = lr2.predict(cv2_blend_x)\n",
    "evaluate(cv1_y, cv1_blend_y_2, \"    cv1 with fit to cv2\")\n",
    "evaluate(cv2_y, cv2_blend_y_2, \"    cv2 with fit to cv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean([0.39047, 0.39053, 0.38797, 0.39050, 0.38861])\n",
    "np.mean([0.37957, 0.38322, 0.38698, 0.38571, 0.38232])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_cy = max(cv_y) * 1.1\n",
    "\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.scatter(cv_y, cv_y_preds, s=1)\n",
    "plt.xlim(0, 70)\n",
    "\n",
    "preds = pd.DataFrame({\"actual\": cv_y, \"pred\": cv_y_preds})\n",
    "preds.boxplot('pred', 'actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[2, 3], [4, 5]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.repeat(0.0,5), np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(cv2_blend_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
