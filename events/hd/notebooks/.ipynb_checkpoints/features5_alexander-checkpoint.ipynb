{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import random\n",
    "random.seed(2016)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import pipeline, grid_search\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = '%s'\n",
    "#loc = '/home/ec2-user/data/hd/features/%s'\n",
    "a_o = np.load(loc % 'train_data.npy')\n",
    "b_o = np.load(loc % 'test_data.npy')\n",
    "a_brand = np.load(loc % 'features_brand_01_train.npy')\n",
    "b_brand = np.load(loc % 'features_brand_01_test.npy')\n",
    "a_other = np.load(loc % 'FEATURES_1d_TRAIN.npy')\n",
    "b_other = np.load(loc % 'FEATURES_1d_TEST.npy')\n",
    "a_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TRAIN.npy')\n",
    "b_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TEST.npy')\n",
    "\n",
    "a_w2vdot = pd.read_pickle(loc % 'W2V_dots_train.df').drop('relevance', axis=1).values\n",
    "b_w2vdot = pd.read_pickle(loc % 'W2V_dots_test.df').drop('relevance', axis=1).values\n",
    "\n",
    "a_w2vdist = np.load(loc % 'W2V_dists_train.npz')['arr_0']\n",
    "b_w2vdist = np.load(loc % 'W2V_dists_test.npz')['arr_0']\n",
    "\n",
    "a_w2v_el = np.load(loc % 'W2V_vecs_train.npz')['arr_0']\n",
    "b_w2v_el = np.load(loc % 'W2V_vecs_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.hstack((a_o, a_brand, a_other, a_w2vdot, a_word_feat, a_w2vdist, a_w2v_el))\n",
    "b = np.hstack((b_o, b_brand, b_other, b_w2vdot, b_word_feat, b_w2vdist, b_w2v_el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53907,), (20160,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train = pd.read_pickle(loc % 'LABELS_TRAIN.df')\n",
    "idx_test = pd.read_pickle(loc % 'LABELS_TEST.df')\n",
    "\n",
    "validation_idx = pd.read_csv(loc % 'valid_set.csv.gz', index_col= 'id').index\n",
    "train_idx = idx_train.index.difference(validation_idx)\n",
    "\n",
    "df_a = pd.DataFrame(a, index=idx_train.index)\n",
    "\n",
    "train_idx.shape, validation_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_training_alex = df_a.loc[train_idx]\n",
    "df_validating_alex = df_a.loc[validation_idx]\n",
    "\n",
    "df_training_alex_label = idx_train.loc[train_idx]\n",
    "df_validating_alex_label = idx_train.loc[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53907, 100), (53907, 1), (20160, 100), (20160, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   TRACK A\n",
    "# without \"co-occurring 6\" features, and only limited number of features\n",
    "X_train = df_training_alex.values[:, 0:100]\n",
    "y_train = df_training_alex_label.values\n",
    "\n",
    "X_test = df_validating_alex.values[:, 0:100]\n",
    "y_test = df_validating_alex_label.values\n",
    "\n",
    "X_train.shape, y_train.shape,  X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53907, 1172), (53907, 1), (20160, 1172), (20160, 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   TRACK B\n",
    "# without \"co-occurring 6\" features\n",
    "X_train = df_training_alex.values\n",
    "y_train = df_training_alex_label.values\n",
    "\n",
    "X_test = df_validating_alex.values\n",
    "y_test = df_validating_alex_label.values\n",
    "\n",
    "X_train.shape, y_train.shape,  X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   TRACK C\n",
    "# with \"co-occurring 6\" features\n",
    "\n",
    "coo_tra = pd.read_csv(loc % 'word_co_train_local.csv.gz')\n",
    "coo_val = pd.read_csv(loc % 'word_co_validate_local.csv.gz')\n",
    "\n",
    "X_train = np.hstack((df_training_alex.values, coo_tra.drop('id', axis=1).values))\n",
    "y_train = df_training_alex_label.values\n",
    "\n",
    "X_test = np.hstack((df_validating_alex.values, coo_val.drop('id', axis=1).values))\n",
    "y_test = df_validating_alex_label.values\n",
    "\n",
    "X_train.shape, y_train.shape,  X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47733228483742429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.Ridge (alpha = 0.6)\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "y_hat = np.minimum(np.maximum(y_hat, 1.0), 3.0)\n",
    "fmean_squared_error(y_hat, y_test)\n",
    "\n",
    "#0.47733228483742429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aas = []\n",
    "for i in range(1,1172+1):\n",
    "    X_train = df_training_alex.values[:, 0:i]\n",
    "    y_train = df_training_alex_label.values\n",
    "\n",
    "    X_test = df_validating_alex.values[:, 0:i]\n",
    "    y_test = df_validating_alex_label.values\n",
    "\n",
    "    clf = linear_model.Ridge (alpha = 0.6)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_test)\n",
    "    y_hat = np.minimum(np.maximum(y_hat, 1.0), 3.0)\n",
    "    aas.append(fmean_squared_error(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10880ecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 8\n",
    "\n",
    "plt.plot(aas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.528935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.530449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.529517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.528955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.528607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.528630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.528360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.497234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.496467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.496647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.496562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.492817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.492667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.492511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.492555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.492257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.492249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.492243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.492189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.492202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.492377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.492222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.492298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.492292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.492291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.490042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.489964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.480031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.479724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.479728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.479705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.479703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.479685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.479589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.479555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.479587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.479590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.479570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.479471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.479470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.479492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.479505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.479390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.479423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.479428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.479432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.479417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.479464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.479455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.479441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.479442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.479443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.479443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.479428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.479403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.478050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.477332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.528935\n",
       "1    0.529975\n",
       "2    0.530451\n",
       "3    0.530449\n",
       "4    0.530124\n",
       "5    0.529517\n",
       "6    0.528955\n",
       "7    0.528607\n",
       "8    0.528630\n",
       "9    0.528360\n",
       "10   0.497234\n",
       "11   0.496467\n",
       "12   0.496647\n",
       "13   0.496562\n",
       "14   0.492817\n",
       "15   0.492667\n",
       "16   0.492511\n",
       "17   0.492555\n",
       "18   0.492257\n",
       "19   0.492249\n",
       "20   0.492243\n",
       "21   0.492189\n",
       "22   0.492202\n",
       "23   0.492377\n",
       "24   0.492222\n",
       "25   0.492298\n",
       "26   0.492292\n",
       "27   0.492291\n",
       "28   0.490042\n",
       "29   0.489964\n",
       "..        ...\n",
       "161  0.480031\n",
       "162  0.479724\n",
       "163  0.479728\n",
       "164  0.479705\n",
       "165  0.479703\n",
       "166  0.479685\n",
       "167  0.479589\n",
       "168  0.479555\n",
       "169  0.479587\n",
       "170  0.479590\n",
       "171  0.479570\n",
       "172  0.479471\n",
       "173  0.479470\n",
       "174  0.479492\n",
       "175  0.479505\n",
       "176  0.479390\n",
       "177  0.479423\n",
       "178  0.479428\n",
       "179  0.479432\n",
       "180  0.479417\n",
       "181  0.479464\n",
       "182  0.479455\n",
       "183  0.479441\n",
       "184  0.479442\n",
       "185  0.479443\n",
       "186  0.479443\n",
       "187  0.479428\n",
       "188  0.479403\n",
       "189  0.478050\n",
       "190  0.477332\n",
       "\n",
       "[191 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(aas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74067, 191), (53907, 190), (20160, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, X_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checked LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_num_round():\n",
    "    return np.random.randint(750, 950)\n",
    "\n",
    "num_round = 10000\n",
    "\n",
    "# TRAIN AS SELF\n",
    "param = {'max_depth':9, \n",
    "         'eta':0.1, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.3,\n",
    "         'subsample':0.9,\n",
    "         'nthread':8,\n",
    "         'silent': True\n",
    "        }\n",
    "# GOOD <<\n",
    "param = {'max_depth':7, \n",
    "         'eta':0.03, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.7, #7\n",
    "         'subsample':0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }\n",
    "param = {'max_depth':9, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.7, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    }\n",
    "param = {'max_depth':6, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.6, #7\n",
    "     'subsample':0.8,  #8\n",
    "     'min_child_weight': 5.0,\n",
    "     'nthread':32,\n",
    "     'silent': True,\n",
    "     'seed': 37\n",
    "    }\n",
    "\n",
    "param = {'max_depth':7, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.6, #7\n",
    "     'subsample':0.8,  #8\n",
    "     'min_child_weight': 5.0,\n",
    "     'nthread':32,\n",
    "     'silent': True,\n",
    "     'seed': 39\n",
    "    }\n",
    "\n",
    "num_round = 200000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=100, verbose_eval=10)\n",
    "#bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 700x trees  -  cv: 0.4377 (seed 147)\n",
    "param = {'max_depth':9, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.3, #0.8 #7  0.4449\n",
    "         'subsample':0.8, #0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }  \n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=30, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ggX_train = xgb.DMatrix(data=a_full, label=dtrain.get_label())\n",
    "ggX_test = xgb.DMatrix(data=b_full)\n",
    "\n",
    "idx_train = pd.read_pickle(loc % 'LABELS_TRAIN.df')\n",
    "idx_test = pd.read_pickle(loc % 'LABELS_TEST.df')\n",
    "\n",
    "num_round = 1550\n",
    "bst = xgb.train( param, ggX_train, num_round, [(gX_test,'test')], verbose_eval=50)\n",
    "\n",
    "y_pred = bst.predict(ggX_test)\n",
    "y_pred_bounded = np.minimum(np.maximum(y_pred, 1.0), 3.0)\n",
    "idx_test['relevance'] = y_pred_bounded\n",
    "idx_test.to_csv('submission_RenatPawel_combined_features_xgboost_0408_0137.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gzip submission_xgboost_words_0405_1646.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1500 trees \n",
    "param = {'max_depth':9, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.8, #0.8 #7  0.4449\n",
    "         'subsample':0.9, #0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }  \n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=15, verbose_eval=10)\n",
    "\n",
    "with 0.30 and 1479\n",
    "cv:  0.4493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = '%s'\n",
    "\n",
    "aaa = pd.read_pickle(loc % 'WOQTAL_TRAIN_ALL')\n",
    "bbb = pd.read_pickle(loc % 'WOQTAL_TEST_ALL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa[aaa['woqt1'] > 0.127]['relevance'].mean(), aaa[aaa['woqt1'] < 0.127]['relevance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa[aaa['woqt2'] > 0.329895]['relevance'].mean(), aaa[aaa['woqt2'] < 0.329895]['relevance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa['woqt2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = aaa.drop('relevance', axis=1)\n",
    "bb = bbb.drop('relevance', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa.reset_index().to_csv('word_co_train.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.reset_index().to_csv('word_co_test.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
