{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn import pipeline, model_selection\n",
    "from sklearn import pipeline, grid_search\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "import re\n",
    "import random\n",
    "random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOC = '/Users/rbekbolatov/data/kaggle/homedepot/'\n",
    "df_train = pd.read_csv(LOC + 'train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(LOC + 'test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv(LOC + 'product_descriptions.csv')\n",
    "df_attr = pd.read_csv(LOC + 'attributes.csv')\n",
    "df_matches = pd.read_csv(LOC + 'matched_strings_clean.csv').fillna(\"\")\n",
    "\n",
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"}).fillna(\"\")\n",
    "num_train = df_train.shape[0]\n",
    "# (74067, 5), (166693, 4) -> df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True) # (240760, 5)\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_matches, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>tit</th>\n",
       "      <th>tit2</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc2</th>\n",
       "      <th>attributes</th>\n",
       "      <th>mfgbrand</th>\n",
       "      <th>mfgbrand2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "      <td>angle</td>\n",
       "      <td></td>\n",
       "      <td>angled, angles</td>\n",
       "      <td></td>\n",
       "      <td>angled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      product_title  product_uid  relevance  \\\n",
       "0   2  Simpson Strong-Tie 12-Gauge Angle       100001        3.0   \n",
       "1   3  Simpson Strong-Tie 12-Gauge Angle       100001        2.5   \n",
       "\n",
       "     search_term                                product_description  \\\n",
       "0  angle bracket  Not only do angles make joints stronger, they ...   \n",
       "1      l bracket  Not only do angles make joints stronger, they ...   \n",
       "\n",
       "                brand    tit tit2            desc desc2 attributes mfgbrand  \\\n",
       "0  Simpson Strong-Tie  angle       angled, angles           angled            \n",
       "1  Simpson Strong-Tie                                                         \n",
       "\n",
       "  mfgbrand2  \n",
       "0            \n",
       "1            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern_camel = re.compile(r\"([a-z]+)([0-9A]|([A-Z][^ ]+))\")\n",
    "pattern_lcase_number = re.compile(r\"([a-z])([0-9])\")\n",
    "pattern_digit_lcase = re.compile(r\"([0-9])([a-z])\")\n",
    "pattern_s = re.compile(r\"([a-z])'s\")\n",
    "pattern_number_commas = re.compile(r\"([0-9]),([0-9])\")\n",
    "\n",
    "    \n",
    "# 4x2\n",
    "XBY = \"xby\"\n",
    "pattern_xby_d = re.compile(r\"(x[0-9])\")\n",
    "pattern_d_xby = re.compile(r\"([0-9])x\")\n",
    "\n",
    "# units\n",
    "pattern_inch = re.compile(r\"([0-9])( *)(inches|inch|in|')\\.?\")\n",
    "pattern_foot = re.compile(r\"([0-9])( *)(foot|feet|ft|''|\\\")\\.?\")\n",
    "pattern_pound = re.compile(r\"([0-9])( *)(pounds|pound|lbs|lb)\\.?\")\n",
    "pattern_sqft = re.compile(r\"([0-9])( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\")\n",
    "pattern_gallons = re.compile(r\"([0-9])( *)(gallons|gallon|gal)\\.?\")\n",
    "pattern_oz = re.compile(r\"([0-9])( *)(ounces|ounce|oz)\\.?\")\n",
    "pattern_cm = re.compile(r\"([0-9])( *)(centimeters|cm)\\.?\")\n",
    "pattern_mm = re.compile(r\"([0-9])( *)(milimeters|mm)\\.?\")\n",
    "pattern_deg = re.compile(r\"([0-9])( *)(degrees|degree)\\.?\")\n",
    "pattern_volt = re.compile(r\"([0-9])( *)(volts|volt)\\.?\")\n",
    "pattern_watt = re.compile(r\"([0-9])( *)(watts|watt)\\.?\")\n",
    "pattern_amp = re.compile(r\"([0-9])( *)(amperes|ampere|amps|amp)\\.?\")\n",
    "pattern_kamp = re.compile(r\"([0-9])( *)(kiloamperes|kiloampere|kamps|kamp|ka)\\.?\")\n",
    "\n",
    "# split\n",
    "pattern_split = re.compile('[^0-9a-z]')\n",
    "\n",
    "known_words = set([\"the\", \"a\", \"an\",\n",
    "    \"this\", \"that\", \"which\", \"whose\",\n",
    "    \"other\", \"and\", \"or\",\n",
    "    \"be\", \"is\", \"are\", \"been\",\n",
    "    \"have\", \"has\", \"had\",\n",
    "    \"can\", \"could\", \"will\", \"would\",\n",
    "    \"go\", \"gone\", \"see\", \"seen\",\n",
    "    \"all\", \"some\", \"any\", \"most\", \"several\", \"no\", \"none\", \"nothing\",\n",
    "    \"as\", \"of\", \"in\", \"on\", \"at\", \"over\", \"from\", \"to\",\n",
    "    \"with\", \"through\", \"for\", \"when\", \"then\",\n",
    "    \"new\", \"old\",\n",
    "    \"you\", \"your\", \"yours\", \"me\", \"i\", \"my\", \"mine\", \"it\", \"its\"])\n",
    "\n",
    "def str_stem(s): \n",
    "    if isinstance(s, str) or isinstance(s, unicode):\n",
    "        \n",
    "        s = pattern_camel.sub(r\"\\1 \\2\", s)\n",
    "        s = pattern_lcase_number.sub(r\"\\1 \\2\", s)\n",
    "        s = pattern_digit_lcase.sub(r\"\\1 \\2\", s)\n",
    "        s = pattern_number_commas.sub(r\"\\1\\2\", s)\n",
    "        s = pattern_s.sub(r\"\\1\", s)\n",
    "        \n",
    "        \n",
    "        s = s.lower().strip()\n",
    "        \n",
    "        # 4ft x 2ft\n",
    "        s = s.replace(\" x \",\" \" + XBY + \" \")\n",
    "        s = s.replace(\"*\",\" \" + XBY + \" \")        \n",
    "        s = s.replace(\" by \",\" \" + XBY)\n",
    "        s = pattern_xby_d.sub(\" \" + XBY + \" \\1\", s)\n",
    "        s = pattern_d_xby.sub(\"\\1 \" + XBY + \" \", s)\n",
    "        \n",
    "        # units\n",
    "        s = pattern_inch.sub(r\"\\1 inch \", s)\n",
    "        s = pattern_foot.sub(r\"\\1 foot \", s)\n",
    "        s = pattern_pound.sub(r\"\\1 pound \", s)\n",
    "        s = pattern_sqft.sub(r\"\\1 sqft \", s)\n",
    "        s = pattern_gallons.sub(r\"\\1 gal \", s)\n",
    "        s = pattern_oz.sub(r\"\\1 oz \", s)\n",
    "        s = pattern_cm.sub(r\"\\1 cm \", s)\n",
    "        s = pattern_mm.sub(r\"\\1 mm \", s)\n",
    "        s = pattern_deg.sub(r\"\\1 deg \", s)\n",
    "        s = pattern_volt.sub(r\"\\1 volt \", s)\n",
    "        s = pattern_watt.sub(r\"\\1 watt \", s)\n",
    "        s = pattern_amp.sub(r\"\\1 amp \", s)\n",
    "        s = pattern_kamp.sub(r\"\\1 kamp \", s)\n",
    "        \n",
    "        # some by hand\n",
    "        s = s.replace(\"whirpool\",\"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolga\", \"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n",
    "        s = s.replace(\"pressure-treated\",\"pressure-treated pt\")\n",
    "        \n",
    "        s = ' '.join([x for x in pattern_split.split(s) if x and x not in known_words])\n",
    "        return s\n",
    "    else:\n",
    "        #raise ValueError(\"Type of \" + str(s) + \" is \" + str(type(s)))\n",
    "        #print \"HUY\"\n",
    "        return 'null'\n",
    "    \n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt\n",
    "\n",
    "def str_whole_word(str1, str2, i_):\n",
    "    cnt = 0\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_)\n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# id\tproduct_title\tproduct_uid\trelevance\tsearch_term\tproduct_description\tbrand\n",
    "# id, relevance, search_term, product_title, product_description, (product_uid,) brand  [product_info, attr]\n",
    "class cust_regression_vals(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, hd_searches):\n",
    "        d_col_drops=['id','relevance','search_term','product_title','product_description','product_info','attr','brand'] + \\\n",
    "        ['tit', 'tit2', 'desc', 'desc2', 'attributes', 'mfgbrand', 'mfgbrand2'] + \\\n",
    "        ['brand_feature'] #['ratio_brand']\n",
    "        #[] #['ratio_title', 'ratio_description', 'ratio_brand']\n",
    "        hd_searches = hd_searches.drop(d_col_drops,axis=1).values\n",
    "        return hd_searches\n",
    "\n",
    "class cust_txt_col(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].apply(str)\n",
    "\n",
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "def fmse(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions)\n",
    "\n",
    "#RMSE  = make_scorer(fmse, greater_is_better=False)\n",
    "RMSE  = make_scorer(fmean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([x for x in \"a,s4\".split(\",\") if x and not re.findall(r'[0-9]', x)])\n",
    "# df_all['query_in_title'] = df_all['tit'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "# df_all['query_in_description'] = df_all['desc'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "# df_all['query_in_attrs'] = df_all['attributes'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "# df_all['query_in_brand'] = df_all['mfgbrand'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "if re.match(r'^[0-9]+$', \"srs94343\"):\n",
    "    print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['desc'].map(lambda y: len([x for x in y.split(\",\") if x and not re.findall(r'[0-9]', x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Features Set: 0.15 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#comment out the lines below use df_all.csv for further grid search testing\n",
    "#if adding features consider any drops on the 'cust_regression_vals' class\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "df_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x: max(1, len(x.split()))).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x: len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['letters_query'] = df_all['search_term'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_title'] = df_all['product_title'].map(lambda x:len(x)).astype(np.int64)\n",
    "df_all['letters_desc'] = df_all['product_description'].map(lambda x:len(x)).astype(np.int64)\n",
    "df_all['letters_brand'] = df_all['brand'].map(lambda x:len(x)).astype(np.int64)\n",
    "\n",
    "###############################\n",
    "# df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\n",
    "# df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))\n",
    "\n",
    "# df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "# df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "# df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "\n",
    "df_all['query_in_title'] = df_all['tit'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_description'] = df_all['desc'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_attrs'] = df_all['attributes'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_brand'] = df_all['mfgbrand'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "\n",
    "df_all['letters_query_in_title'] = df_all['tit'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_description'] = df_all['desc'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_attrs'] = df_all['attributes'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_brand'] = df_all['mfgbrand'].map(lambda x: len(x)).astype(np.int64)\n",
    "\n",
    "\n",
    "df_all['query_in_title2'] = df_all['tit2'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_description2'] = df_all['desc2'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_brand2'] = df_all['mfgbrand2'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "\n",
    "\n",
    "df_all['letters_query_in_title2'] = df_all['tit2'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_description2'] = df_all['desc2'].map(lambda x: len(x)).astype(np.int64)\n",
    "\n",
    "df_all['ratio_letters_query_in_title'] = df_all['letters_query_in_title2']/(df_all['letters_query_in_title'] + 1)\n",
    "df_all['ratio_letters_query_in_descr'] = df_all['letters_query_in_description2']/(df_all['letters_query_in_description'] + 1)\n",
    "\n",
    "\n",
    "df_all['query_in_title_num'] = df_all['tit'].map(lambda y: len([x for x in y.split(\",\") if x and re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_description_num'] = df_all['desc'].map(lambda y: len([x for x in y.split(\",\") if x and re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_attrs_num'] = df_all['attributes'].map(lambda y: len([x for x in y.split(\",\") if x and re.match(r'^[0-9]+$', x)]))\n",
    "\n",
    "\n",
    "\n",
    "#df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "#df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "#df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "###############################\n",
    "\n",
    "\n",
    "df_all['ratio_title'] = df_all['query_in_title']/df_all['len_of_query']\n",
    "df_all['ratio_description'] = df_all['query_in_description']/df_all['len_of_query']\n",
    "\n",
    "# df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']\n",
    "# df_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']\n",
    "# df_all['ratio_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\n",
    "\n",
    "\n",
    "df_brand = pd.unique(df_all.brand.ravel())\n",
    "d={}\n",
    "i = 1\n",
    "for s in df_brand:\n",
    "    d[s]=i\n",
    "    i+=1\n",
    "df_all['brand_feature'] = df_all['brand'].map(lambda x: d[x])\n",
    "#df_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x))\n",
    "\n",
    "#df_all.to_csv('df_all_322_1.csv')\n",
    "#df_all = pd.read_csv('df_all.csv', encoding=\"ISO-8859-1\", index_col=0)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train[:]\n",
    "X_test = df_test[:]\n",
    "print(\"--- Features Set: %s minutes ---\" % round(((time.time() - start_time)/60), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>tit</th>\n",
       "      <th>tit2</th>\n",
       "      <th>desc</th>\n",
       "      <th>...</th>\n",
       "      <th>letters_query_in_title2</th>\n",
       "      <th>letters_query_in_description2</th>\n",
       "      <th>query_in_title_num</th>\n",
       "      <th>query_in_description_num</th>\n",
       "      <th>query_in_attrs_num</th>\n",
       "      <th>ratio_title</th>\n",
       "      <th>ratio_description</th>\n",
       "      <th>brand_feature</th>\n",
       "      <th>ratio_letters_query_in_title</th>\n",
       "      <th>ratio_letters_query_in_descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>simpson strong tie 12 gauge angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>not only do angles make joints stronger they a...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td>angle</td>\n",
       "      <td></td>\n",
       "      <td>angled, angles</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{u'brand': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>simpson strong tie 12 gauge angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>not only do angles make joints stronger they a...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'brand': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      product_title  product_uid  relevance  \\\n",
       "0   2  simpson strong tie 12 gauge angle       100001        3.0   \n",
       "1   3  simpson strong tie 12 gauge angle       100001        2.5   \n",
       "\n",
       "     search_term                                product_description  \\\n",
       "0  angle bracket  not only do angles make joints stronger they a...   \n",
       "1      l bracket  not only do angles make joints stronger they a...   \n",
       "\n",
       "                brand    tit tit2            desc  \\\n",
       "0  simpson strong tie  angle       angled, angles   \n",
       "1  simpson strong tie                               \n",
       "\n",
       "               ...              letters_query_in_title2  \\\n",
       "0              ...                                    0   \n",
       "1              ...                                    0   \n",
       "\n",
       "  letters_query_in_description2 query_in_title_num query_in_description_num  \\\n",
       "0                             0                  0                        0   \n",
       "1                             0                  0                        0   \n",
       "\n",
       "  query_in_attrs_num ratio_title  ratio_description  brand_feature  \\\n",
       "0                  0         0.5                  1  {u'brand': 1}   \n",
       "1                  0         0.0                  0  {u'brand': 1}   \n",
       "\n",
       "   ratio_letters_query_in_title  ratio_letters_query_in_descr  \n",
       "0                             0                             0  \n",
       "1                             0                             0  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[0:2]\n",
    "#df_all['query_in_title'] + 1\n",
    "#df_all['query_in_title2']/(df_all['query_in_title'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD FROM SAVED\n",
    "#df_all = pd.read_csv('df_all.csv', encoding=\"ISO-8859-1\", index_col=0)\n",
    "#df_all = pd.read_csv('df_all_322_1.csv', encoding=\"ISO-8859-1\", index_col=0)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train[:]\n",
    "X_test = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_all[300:320][['relevance', 'product_title', 'search_term', 'product_description']]\n",
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "#tsvd = TruncatedSVD(n_components=10, random_state = 2016)\n",
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# dictvect = DictVectorizer()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohenc = OneHotEncoder()\n",
    "randomForestRegressor = RandomForestRegressor(n_estimators = 100, min_samples_leaf=3, n_jobs = -1, random_state = 3017, verbose = 1)\n",
    "\n",
    "clf = pipeline.Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                    transformer_list = [\n",
    "                        ('cst',  cust_regression_vals()),  \n",
    "                    \n",
    "#                         ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n",
    "#                         ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])),\n",
    "#                         ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n",
    "#                         ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))\n",
    "                    \n",
    "#                         ('txt1', pipeline.Pipeline([ ('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf)  ])),\n",
    "#                         ('txt2', pipeline.Pipeline([ ('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf)  ])),\n",
    "#                         ('txt3', pipeline.Pipeline([ ('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf) ])),\n",
    "#                         ('txt4', pipeline.Pipeline([ ('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf) ]))\n",
    "                    \n",
    "#                         ('brandf', pipeline.Pipeline([ ('s5', cust_txt_col(key='brand_feature')), ('ohenc', ohenc)  ])),\n",
    "                        ],\n",
    "                    transformer_weights = {\n",
    "                        'cst': 1.0,\n",
    "#                         'txt1': 0.5,\n",
    "#                         'txt2': 0.25,\n",
    "#                         'txt3': 0.5,\n",
    "#                         'txt4': 0.5\n",
    "#                         'brandf': 1.0\n",
    "                        },\n",
    "                n_jobs = -1\n",
    "                )), \n",
    "        ('rfr', randomForestRegressor)])\n",
    "\n",
    "#clf.set_params(rfr__max_features=10, rfr__max_depth=20)\n",
    "#clf.fit(X_train, y_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] rfr__max_features=2, rfr__max_depth=30 ..........................\n",
      "[CV] rfr__max_features=2, rfr__max_depth=30 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:449: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:449: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Library/Python/2.7/site-packages/scipy/sparse/compressed.py:233: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  \" != instead.\", SparseEfficiencyWarning)\n",
      "/Library/Python/2.7/site-packages/scipy/sparse/compressed.py:233: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  \" != instead.\", SparseEfficiencyWarning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Library/Python/2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x10abee6b0, file \"/Lib...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Library/Python/2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Library/Python/2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Library/Python/2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x10abee6b0, file \"/Lib...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Library/Python/2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Library/Python/2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Library/Python/2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    384     def start(self):\n    385         if self.poller is not None:\n    386             self.poller.start()\n    387         self.kernel.start()\n    388         try:\n--> 389             ioloop.IOLoop.instance().start()\n    390         except KeyboardInterrupt:\n    391             pass\n    392 \n    393 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Library/Python/2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    835                 self._events.update(event_pairs)\n    836                 while self._events:\n    837                     fd, events = self._events.popitem()\n    838                     try:\n    839                         fd_obj, handler_func = self._handlers[fd]\n--> 840                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    841                     except (OSError, IOError) as e:\n    842                         if errno_from_exception(e) == errno.EPIPE:\n    843                             # Happens when the client closes the connection\n    844                             pass\n\n...........................................................................\n/Library/Python/2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Library/Python/2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'0042B04B01144372BBC93CC7A136A800', u'msg_type': u'execute_request', u'session': u'6B6372B8C091458DA5AF65371F589570', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'0042B04B01144372BBC93CC7A136A800', 'msg_type': u'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['6B6372B8C091458DA5AF65371F589570']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'0042B04B01144372BBC93CC7A136A800', u'msg_type': u'execute_request', u'session': u'6B6372B8C091458DA5AF65371F589570', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'0042B04B01144372BBC93CC7A136A800', 'msg_type': u'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['6B6372B8C091458DA5AF65371F589570'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'0042B04B01144372BBC93CC7A136A800', u'msg_type': u'execute_request', u'session': u'6B6372B8C091458DA5AF65371F589570', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'0042B04B01144372BBC93CC7A136A800', 'msg_type': u'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360 \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>], cell_name='<ipython-input-36-b98650b4b979>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x12dec26b0, file \"<ipython-input-36-b98650b4b979>\", line 5>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x12dec26b0, file \"<ipython-input-36-b98650b4b979>\", line 5>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x12dec26b0, file \"<ipython-input-36-b98650b4b979>\", line 5>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'In': ['', u'import time\\nimport numpy as np\\nimport pandas...r\\n\\nimport re\\nimport random\\nrandom.seed(2016)', u'LOC = \\'/Users/rbekbolatov/data/kaggle/homedep...5), (166693, 4) -> df_train.shape, df_test.shape', u\"df_all = pd.concat((df_train, df_test), axis=0...\\ndf_all = pd.merge(df_all, df_matches, on='id')\", u'df_all[0:2]', u'pattern_camel = re.compile(r\"([a-z]+)([0-9A]|(...'] = df_all[\\'brand\\'].map(lambda x:str_stem(x))', u'def str_common_word(str1, str2):\\n    words, c...= 1\\n            i_ += len(str1)\\n    return cnt', u\"# id\\tproduct_title\\tproduct_uid\\trelevance\\ts...er(fmean_squared_error, greater_is_better=False)\", u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", ...], 'LOC': '/Users/rbekbolatov/data/kaggle/homedepot/', 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {4:    id                      product_title  produc...      \n\n  mfgbrand2  \n0            \n1            , 30:    id                      product_title  produc...                       0  \n\n[2 rows x 45 columns]}, 'RMSE': make_scorer(fmean_squared_error, greater_is_better=False), 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'In': ['', u'import time\\nimport numpy as np\\nimport pandas...r\\n\\nimport re\\nimport random\\nrandom.seed(2016)', u'LOC = \\'/Users/rbekbolatov/data/kaggle/homedep...5), (166693, 4) -> df_train.shape, df_test.shape', u\"df_all = pd.concat((df_train, df_test), axis=0...\\ndf_all = pd.merge(df_all, df_matches, on='id')\", u'df_all[0:2]', u'pattern_camel = re.compile(r\"([a-z]+)([0-9A]|(...'] = df_all[\\'brand\\'].map(lambda x:str_stem(x))', u'def str_common_word(str1, str2):\\n    words, c...= 1\\n            i_ += len(str1)\\n    return cnt', u\"# id\\tproduct_title\\tproduct_uid\\trelevance\\ts...er(fmean_squared_error, greater_is_better=False)\", u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", ...], 'LOC': '/Users/rbekbolatov/data/kaggle/homedepot/', 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {4:    id                      product_title  produc...      \n\n  mfgbrand2  \n0            \n1            , 30:    id                      product_title  produc...                       0  \n\n[2 rows x 45 columns]}, 'RMSE': make_scorer(fmean_squared_error, greater_is_better=False), 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/rbekbolatov/repos/gh/bekbolatov/kaggle/events/hd/notebooks/<ipython-input-36-b98650b4b979> in <module>()\n      1 \n      2 start_time = time.time()\n      3 \n      4 param_grid = {'rfr__max_features': [2], 'rfr__max_depth': [30]}\n----> 5 model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 3, verbose = 20, scoring=RMSE)\n      6 model.fit(X_train, y_train)\n      7 \n      8 print(\"--- Training: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n      9 \n     10 print(\"Best parameters found by grid search:\")\n     11 print(model.best_params_)\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ror, greater_is_better=False),\n       verbose=20), X=           id                                   ...            0.866667  \n\n[74067 rows x 45 columns], y=array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...or, greater_is_better=False),\n       verbose=20)>\n        X =            id                                   ...            0.866667  \n\n[74067 rows x 45 columns]\n        y = array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33])\n        self.param_grid = {'rfr__max_depth': [30], 'rfr__max_features': [2]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ror, greater_is_better=False),\n       verbose=20), X=           id                                   ...            0.866667  \n\n[74067 rows x 45 columns], y=array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Wed Mar 23 03:45:42 2016\nPID: 41621                                   Python 2.7.10: /usr/bin/python\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1...=3017,\n           verbose=1, warm_start=False))]), X=           id                                   ...            0.866667  \n\n[74067 rows x 45 columns], y=array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33]), scorer=make_scorer(fmean_squared_error, greater_is_better=False), train=array([24689, 24690, 24691, ..., 74064, 74065, 74066]), test=array([    0,     1,     2, ..., 24686, 24687, 24688]), verbose=20, parameters={'rfr__max_depth': 30, 'rfr__max_features': 2}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1454 \n   1455     try:\n   1456         if y_train is None:\n   1457             estimator.fit(X_train, **fit_params)\n   1458         else:\n-> 1459             estimator.fit(X_train, y_train, **fit_params)\n   1460 \n   1461     except Exception as e:\n   1462         if error_score == 'raise':\n   1463             raise\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/pipeline.pyc in fit(self=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1...=3017,\n           verbose=1, warm_start=False))]), X=           id                                   ...            0.866667  \n\n[49378 rows x 45 columns], y=array([ 2.67,  2.  ,  2.33, ...,  2.33,  3.  ,  2.33]), **fit_params={})\n    135             pipeline.\n    136         y : iterable, default=None\n    137             Training targets. Must fulfill label requirements for all steps of\n    138             the pipeline.\n    139         \"\"\"\n--> 140         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n    141         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    142         return self\n    143 \n    144     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/pipeline.pyc in _pre_transform(self=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1...=3017,\n           verbose=1, warm_start=False))]), X=           id                                   ...            0.866667  \n\n[49378 rows x 45 columns], y=array([ 2.67,  2.  ,  2.33, ...,  2.33,  3.  ,  2.33]), **fit_params={})\n    116             step, param = pname.split('__', 1)\n    117             fit_params_steps[step][param] = pval\n    118         Xt = X\n    119         for name, transform in self.steps[:-1]:\n    120             if hasattr(transform, \"fit_transform\"):\n--> 121                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n    122             else:\n    123                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    124                               .transform(Xt)\n    125         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/pipeline.pyc in fit_transform(self=FeatureUnion(n_jobs=-1,\n       transformer_list=... transformer_weights={'cst': 1.0, 'brandf': 1.0}), X=           id                                   ...            0.866667  \n\n[49378 rows x 45 columns], y=array([ 2.67,  2.  ,  2.33, ...,  2.33,  3.  ,  2.33]), **fit_params={})\n    449             for name, trans in self.transformer_list)\n    450 \n    451         Xs, transformers = zip(*result)\n    452         self._update_transformer_list(transformers)\n    453         if any(sparse.issparse(f) for f in Xs):\n--> 454             Xs = sparse.hstack(Xs).tocsr()\n    455         else:\n    456             Xs = np.hstack(Xs)\n    457         return Xs\n    458 \n\n...........................................................................\n/Library/Python/2.7/site-packages/scipy/sparse/construct.pyc in hstack(blocks=(array([[  1.21724000e+05,   3.00000000e+00,   1....000000e-01,   8.80000000e-01,   8.66666667e-01]]), <1x49378 sparse matrix of type '<type 'numpy.flo... stored elements in Compressed Sparse Row format>), format=None, dtype=None)\n    451     >>> hstack([A,B]).toarray()\n    452     array([[1, 2, 5],\n    453            [3, 4, 6]])\n    454 \n    455     \"\"\"\n--> 456     return bmat([blocks], format=format, dtype=dtype)\n    457 \n    458 \n    459 def vstack(blocks, format=None, dtype=None):\n    460     \"\"\"\n\n...........................................................................\n/Library/Python/2.7/site-packages/scipy/sparse/construct.pyc in bmat(blocks=array([[ <49378x29 sparse matrix of type '<type ...d elements in COOrdinate format>]], dtype=object), format=None, dtype=None)\n    568 \n    569                 if brow_lengths[i] == 0:\n    570                     brow_lengths[i] = A.shape[0]\n    571                 else:\n    572                     if brow_lengths[i] != A.shape[0]:\n--> 573                         raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\n    574 \n    575                 if bcol_lengths[j] == 0:\n    576                     bcol_lengths[j] = A.shape[1]\n    577                 else:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b98650b4b979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'rfr__max_features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rfr__max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Training: %s minutes ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 for train, test in cv)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m                         \u001b[0;31m# Convert this to a JoblibException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                         \u001b[0mexception_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Library/Python/2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x10abee6b0, file \"/Lib...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Library/Python/2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Library/Python/2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Library/Python/2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x10abee6b0, file \"/Lib...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Library/Python/2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Library/Python/2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Library/Python/2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    384     def start(self):\n    385         if self.poller is not None:\n    386             self.poller.start()\n    387         self.kernel.start()\n    388         try:\n--> 389             ioloop.IOLoop.instance().start()\n    390         except KeyboardInterrupt:\n    391             pass\n    392 \n    393 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Library/Python/2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    835                 self._events.update(event_pairs)\n    836                 while self._events:\n    837                     fd, events = self._events.popitem()\n    838                     try:\n    839                         fd_obj, handler_func = self._handlers[fd]\n--> 840                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    841                     except (OSError, IOError) as e:\n    842                         if errno_from_exception(e) == errno.EPIPE:\n    843                             # Happens when the client closes the connection\n    844                             pass\n\n...........................................................................\n/Library/Python/2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Library/Python/2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'0042B04B01144372BBC93CC7A136A800', u'msg_type': u'execute_request', u'session': u'6B6372B8C091458DA5AF65371F589570', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'0042B04B01144372BBC93CC7A136A800', 'msg_type': u'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['6B6372B8C091458DA5AF65371F589570']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'0042B04B01144372BBC93CC7A136A800', u'msg_type': u'execute_request', u'session': u'6B6372B8C091458DA5AF65371F589570', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'0042B04B01144372BBC93CC7A136A800', 'msg_type': u'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['6B6372B8C091458DA5AF65371F589570'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'0042B04B01144372BBC93CC7A136A800', u'msg_type': u'execute_request', u'session': u'6B6372B8C091458DA5AF65371F589570', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'0042B04B01144372BBC93CC7A136A800', 'msg_type': u'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360 \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Library/Python/2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>], cell_name='<ipython-input-36-b98650b4b979>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x12dec26b0, file \"<ipython-input-36-b98650b4b979>\", line 5>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x12dec26b0, file \"<ipython-input-36-b98650b4b979>\", line 5>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x12dec26b0, file \"<ipython-input-36-b98650b4b979>\", line 5>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'In': ['', u'import time\\nimport numpy as np\\nimport pandas...r\\n\\nimport re\\nimport random\\nrandom.seed(2016)', u'LOC = \\'/Users/rbekbolatov/data/kaggle/homedep...5), (166693, 4) -> df_train.shape, df_test.shape', u\"df_all = pd.concat((df_train, df_test), axis=0...\\ndf_all = pd.merge(df_all, df_matches, on='id')\", u'df_all[0:2]', u'pattern_camel = re.compile(r\"([a-z]+)([0-9A]|(...'] = df_all[\\'brand\\'].map(lambda x:str_stem(x))', u'def str_common_word(str1, str2):\\n    words, c...= 1\\n            i_ += len(str1)\\n    return cnt', u\"# id\\tproduct_title\\tproduct_uid\\trelevance\\ts...er(fmean_squared_error, greater_is_better=False)\", u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", ...], 'LOC': '/Users/rbekbolatov/data/kaggle/homedepot/', 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {4:    id                      product_title  produc...      \n\n  mfgbrand2  \n0            \n1            , 30:    id                      product_title  produc...                       0  \n\n[2 rows x 45 columns]}, 'RMSE': make_scorer(fmean_squared_error, greater_is_better=False), 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'In': ['', u'import time\\nimport numpy as np\\nimport pandas...r\\n\\nimport re\\nimport random\\nrandom.seed(2016)', u'LOC = \\'/Users/rbekbolatov/data/kaggle/homedep...5), (166693, 4) -> df_train.shape, df_test.shape', u\"df_all = pd.concat((df_train, df_test), axis=0...\\ndf_all = pd.merge(df_all, df_matches, on='id')\", u'df_all[0:2]', u'pattern_camel = re.compile(r\"([a-z]+)([0-9A]|(...'] = df_all[\\'brand\\'].map(lambda x:str_stem(x))', u'def str_common_word(str1, str2):\\n    words, c...= 1\\n            i_ += len(str1)\\n    return cnt', u\"# id\\tproduct_title\\tproduct_uid\\trelevance\\ts...er(fmean_squared_error, greater_is_better=False)\", u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u'# LOAD FROM SAVED\\n#df_all = pd.read_csv(\\'df_...lues\\nX_train = df_train[:]\\nX_test = df_test[:]', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u'start_time = time.time()\\n\\nparam_grid = {\\'rf...rint(\"Best CV score:\")\\nprint(model.best_score_)', u'start_time = time.time()\\n\\n#comment out the l...--\" % round(((time.time() - start_time)/60), 2))', u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", u\"tfidf = TfidfVectorizer(ngram_range=(1, 1), st...depth=20)\\n#clf.fit(X_train, y_train)\\n# X_train\", ...], 'LOC': '/Users/rbekbolatov/data/kaggle/homedepot/', 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {4:    id                      product_title  produc...      \n\n  mfgbrand2  \n0            \n1            , 30:    id                      product_title  produc...                       0  \n\n[2 rows x 45 columns]}, 'RMSE': make_scorer(fmean_squared_error, greater_is_better=False), 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/rbekbolatov/repos/gh/bekbolatov/kaggle/events/hd/notebooks/<ipython-input-36-b98650b4b979> in <module>()\n      1 \n      2 start_time = time.time()\n      3 \n      4 param_grid = {'rfr__max_features': [2], 'rfr__max_depth': [30]}\n----> 5 model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 3, verbose = 20, scoring=RMSE)\n      6 model.fit(X_train, y_train)\n      7 \n      8 print(\"--- Training: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n      9 \n     10 print(\"Best parameters found by grid search:\")\n     11 print(model.best_params_)\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ror, greater_is_better=False),\n       verbose=20), X=           id                                   ...            0.866667  \n\n[74067 rows x 45 columns], y=array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...or, greater_is_better=False),\n       verbose=20)>\n        X =            id                                   ...            0.866667  \n\n[74067 rows x 45 columns]\n        y = array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33])\n        self.param_grid = {'rfr__max_depth': [30], 'rfr__max_features': [2]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ror, greater_is_better=False),\n       verbose=20), X=           id                                   ...            0.866667  \n\n[74067 rows x 45 columns], y=array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Wed Mar 23 03:45:42 2016\nPID: 41621                                   Python 2.7.10: /usr/bin/python\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1...=3017,\n           verbose=1, warm_start=False))]), X=           id                                   ...            0.866667  \n\n[74067 rows x 45 columns], y=array([ 3.  ,  2.5 ,  3.  , ...,  2.33,  3.  ,  2.33]), scorer=make_scorer(fmean_squared_error, greater_is_better=False), train=array([24689, 24690, 24691, ..., 74064, 74065, 74066]), test=array([    0,     1,     2, ..., 24686, 24687, 24688]), verbose=20, parameters={'rfr__max_depth': 30, 'rfr__max_features': 2}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1454 \n   1455     try:\n   1456         if y_train is None:\n   1457             estimator.fit(X_train, **fit_params)\n   1458         else:\n-> 1459             estimator.fit(X_train, y_train, **fit_params)\n   1460 \n   1461     except Exception as e:\n   1462         if error_score == 'raise':\n   1463             raise\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/pipeline.pyc in fit(self=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1...=3017,\n           verbose=1, warm_start=False))]), X=           id                                   ...            0.866667  \n\n[49378 rows x 45 columns], y=array([ 2.67,  2.  ,  2.33, ...,  2.33,  3.  ,  2.33]), **fit_params={})\n    135             pipeline.\n    136         y : iterable, default=None\n    137             Training targets. Must fulfill label requirements for all steps of\n    138             the pipeline.\n    139         \"\"\"\n--> 140         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n    141         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    142         return self\n    143 \n    144     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/pipeline.pyc in _pre_transform(self=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1...=3017,\n           verbose=1, warm_start=False))]), X=           id                                   ...            0.866667  \n\n[49378 rows x 45 columns], y=array([ 2.67,  2.  ,  2.33, ...,  2.33,  3.  ,  2.33]), **fit_params={})\n    116             step, param = pname.split('__', 1)\n    117             fit_params_steps[step][param] = pval\n    118         Xt = X\n    119         for name, transform in self.steps[:-1]:\n    120             if hasattr(transform, \"fit_transform\"):\n--> 121                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n    122             else:\n    123                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    124                               .transform(Xt)\n    125         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Library/Python/2.7/site-packages/sklearn/pipeline.pyc in fit_transform(self=FeatureUnion(n_jobs=-1,\n       transformer_list=... transformer_weights={'cst': 1.0, 'brandf': 1.0}), X=           id                                   ...            0.866667  \n\n[49378 rows x 45 columns], y=array([ 2.67,  2.  ,  2.33, ...,  2.33,  3.  ,  2.33]), **fit_params={})\n    449             for name, trans in self.transformer_list)\n    450 \n    451         Xs, transformers = zip(*result)\n    452         self._update_transformer_list(transformers)\n    453         if any(sparse.issparse(f) for f in Xs):\n--> 454             Xs = sparse.hstack(Xs).tocsr()\n    455         else:\n    456             Xs = np.hstack(Xs)\n    457         return Xs\n    458 \n\n...........................................................................\n/Library/Python/2.7/site-packages/scipy/sparse/construct.pyc in hstack(blocks=(array([[  1.21724000e+05,   3.00000000e+00,   1....000000e-01,   8.80000000e-01,   8.66666667e-01]]), <1x49378 sparse matrix of type '<type 'numpy.flo... stored elements in Compressed Sparse Row format>), format=None, dtype=None)\n    451     >>> hstack([A,B]).toarray()\n    452     array([[1, 2, 5],\n    453            [3, 4, 6]])\n    454 \n    455     \"\"\"\n--> 456     return bmat([blocks], format=format, dtype=dtype)\n    457 \n    458 \n    459 def vstack(blocks, format=None, dtype=None):\n    460     \"\"\"\n\n...........................................................................\n/Library/Python/2.7/site-packages/scipy/sparse/construct.pyc in bmat(blocks=array([[ <49378x29 sparse matrix of type '<type ...d elements in COOrdinate format>]], dtype=object), format=None, dtype=None)\n    568 \n    569                 if brow_lengths[i] == 0:\n    570                     brow_lengths[i] = A.shape[0]\n    571                 else:\n    572                     if brow_lengths[i] != A.shape[0]:\n--> 573                         raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\n    574 \n    575                 if bcol_lengths[j] == 0:\n    576                     bcol_lengths[j] = A.shape[1]\n    577                 else:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = {'rfr__max_features': [2], 'rfr__max_depth': [30]}\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 3, verbose = 20, scoring=RMSE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- Training: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train.ix[3782]\n",
    "inds = pd.isnull(X_train).any(1).nonzero()[0]\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isfinite(X_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isfinite(X_train).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
