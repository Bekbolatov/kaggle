{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn import pipeline, model_selection\n",
    "from sklearn import pipeline, grid_search\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "import re\n",
    "import random\n",
    "random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOC = '/Users/rbekbolatov/data/kaggle/homedepot/'\n",
    "df_train = pd.read_csv(LOC + 'train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(LOC + 'test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv(LOC + 'product_descriptions.csv')\n",
    "df_attr = pd.read_csv(LOC + 'attributes.csv')\n",
    "df_matches = pd.read_csv(LOC + 'matched_strings_clean.csv').fillna(\"\")\n",
    "\n",
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"}).fillna(\"\")\n",
    "num_train = df_train.shape[0]\n",
    "# (74067, 5), (166693, 4) -> df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True) # (240760, 5)\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_matches, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>tit</th>\n",
       "      <th>tit2</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc2</th>\n",
       "      <th>attributes</th>\n",
       "      <th>mfgbrand</th>\n",
       "      <th>mfgbrand2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "      <td>angle</td>\n",
       "      <td></td>\n",
       "      <td>angled, angles</td>\n",
       "      <td></td>\n",
       "      <td>angled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      product_title  product_uid  relevance  \\\n",
       "0   2  Simpson Strong-Tie 12-Gauge Angle       100001        3.0   \n",
       "1   3  Simpson Strong-Tie 12-Gauge Angle       100001        2.5   \n",
       "\n",
       "     search_term                                product_description  \\\n",
       "0  angle bracket  Not only do angles make joints stronger, they ...   \n",
       "1      l bracket  Not only do angles make joints stronger, they ...   \n",
       "\n",
       "                brand    tit tit2            desc desc2 attributes mfgbrand  \\\n",
       "0  Simpson Strong-Tie  angle       angled, angles           angled            \n",
       "1  Simpson Strong-Tie                                                         \n",
       "\n",
       "  mfgbrand2  \n",
       "0            \n",
       "1            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern_camel = re.compile(r\"([a-z]+)([0-9A]|([A-Z][^ ]+))\")\n",
    "pattern_lcase_number = re.compile(r\"([a-z])([0-9])\")\n",
    "pattern_digit_lcase = re.compile(r\"([0-9])([a-z])\")\n",
    "pattern_s = re.compile(r\"([a-z])'s\")\n",
    "pattern_number_commas = re.compile(r\"([0-9]),([0-9])\")\n",
    "\n",
    "    \n",
    "# 4x2\n",
    "XBY = \"xby\"\n",
    "pattern_xby_d = re.compile(r\"(x[0-9])\")\n",
    "pattern_d_xby = re.compile(r\"([0-9])x\")\n",
    "\n",
    "# units\n",
    "pattern_inch = re.compile(r\"([0-9])( *)(inches|inch|in|')\\.?\")\n",
    "pattern_foot = re.compile(r\"([0-9])( *)(foot|feet|ft|''|\\\")\\.?\")\n",
    "pattern_pound = re.compile(r\"([0-9])( *)(pounds|pound|lbs|lb)\\.?\")\n",
    "pattern_sqft = re.compile(r\"([0-9])( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\")\n",
    "pattern_gallons = re.compile(r\"([0-9])( *)(gallons|gallon|gal)\\.?\")\n",
    "pattern_oz = re.compile(r\"([0-9])( *)(ounces|ounce|oz)\\.?\")\n",
    "pattern_cm = re.compile(r\"([0-9])( *)(centimeters|cm)\\.?\")\n",
    "pattern_mm = re.compile(r\"([0-9])( *)(milimeters|mm)\\.?\")\n",
    "pattern_deg = re.compile(r\"([0-9])( *)(degrees|degree)\\.?\")\n",
    "pattern_volt = re.compile(r\"([0-9])( *)(volts|volt)\\.?\")\n",
    "pattern_watt = re.compile(r\"([0-9])( *)(watts|watt)\\.?\")\n",
    "pattern_amp = re.compile(r\"([0-9])( *)(amperes|ampere|amps|amp)\\.?\")\n",
    "pattern_kamp = re.compile(r\"([0-9])( *)(kiloamperes|kiloampere|kamps|kamp|ka)\\.?\")\n",
    "\n",
    "# split\n",
    "pattern_split = re.compile('[^0-9a-z]')\n",
    "\n",
    "known_words = set([\"the\", \"a\", \"an\",\n",
    "    \"this\", \"that\", \"which\", \"whose\",\n",
    "    \"other\", \"and\", \"or\",\n",
    "    \"be\", \"is\", \"are\", \"been\",\n",
    "    \"have\", \"has\", \"had\",\n",
    "    \"can\", \"could\", \"will\", \"would\",\n",
    "    \"go\", \"gone\", \"see\", \"seen\",\n",
    "    \"all\", \"some\", \"any\", \"most\", \"several\", \"no\", \"none\", \"nothing\",\n",
    "    \"as\", \"of\", \"in\", \"on\", \"at\", \"over\", \"from\", \"to\",\n",
    "    \"with\", \"through\", \"for\", \"when\", \"then\",\n",
    "    \"new\", \"old\",\n",
    "    \"you\", \"your\", \"yours\", \"me\", \"i\", \"my\", \"mine\", \"it\", \"its\"])\n",
    "\n",
    "def str_stem(s): \n",
    "    if isinstance(s, str) or isinstance(s, unicode):\n",
    "        \n",
    "        s = pattern_camel.sub(r\"\\1 \\2\", s)\n",
    "        s = pattern_lcase_number.sub(r\"\\1 \\2\", s)\n",
    "        s = pattern_digit_lcase.sub(r\"\\1 \\2\", s)\n",
    "        s = pattern_number_commas.sub(r\"\\1\\2\", s)\n",
    "        s = pattern_s.sub(r\"\\1\", s)\n",
    "        \n",
    "        \n",
    "        s = s.lower().strip()\n",
    "        \n",
    "        # 4ft x 2ft\n",
    "        s = s.replace(\" x \",\" \" + XBY + \" \")\n",
    "        s = s.replace(\"*\",\" \" + XBY + \" \")        \n",
    "        s = s.replace(\" by \",\" \" + XBY)\n",
    "        s = pattern_xby_d.sub(\" \" + XBY + \" \\1\", s)\n",
    "        s = pattern_d_xby.sub(\"\\1 \" + XBY + \" \", s)\n",
    "        \n",
    "        # units\n",
    "        s = pattern_inch.sub(r\"\\1 inch \", s)\n",
    "        s = pattern_foot.sub(r\"\\1 foot \", s)\n",
    "        s = pattern_pound.sub(r\"\\1 pound \", s)\n",
    "        s = pattern_sqft.sub(r\"\\1 sqft \", s)\n",
    "        s = pattern_gallons.sub(r\"\\1 gal \", s)\n",
    "        s = pattern_oz.sub(r\"\\1 oz \", s)\n",
    "        s = pattern_cm.sub(r\"\\1 cm \", s)\n",
    "        s = pattern_mm.sub(r\"\\1 mm \", s)\n",
    "        s = pattern_deg.sub(r\"\\1 deg \", s)\n",
    "        s = pattern_volt.sub(r\"\\1 volt \", s)\n",
    "        s = pattern_watt.sub(r\"\\1 watt \", s)\n",
    "        s = pattern_amp.sub(r\"\\1 amp \", s)\n",
    "        s = pattern_kamp.sub(r\"\\1 kamp \", s)\n",
    "        \n",
    "        # some by hand\n",
    "        s = s.replace(\"whirpool\",\"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolga\", \"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n",
    "        s = s.replace(\"pressure-treated\",\"pressure-treated pt\")\n",
    "        \n",
    "        s = ' '.join([x for x in pattern_split.split(s) if x and x not in known_words])\n",
    "        return s\n",
    "    else:\n",
    "        #raise ValueError(\"Type of \" + str(s) + \" is \" + str(type(s)))\n",
    "        #print \"HUY\"\n",
    "        return 'null'\n",
    "    \n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt\n",
    "\n",
    "def str_whole_word(str1, str2, i_):\n",
    "    cnt = 0\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_)\n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# id\tproduct_title\tproduct_uid\trelevance\tsearch_term\tproduct_description\tbrand\n",
    "# id, relevance, search_term, product_title, product_description, (product_uid,) brand  [product_info, attr]\n",
    "class cust_regression_vals(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, hd_searches):\n",
    "        d_col_drops=['id','relevance','search_term','product_title','product_description','product_info','attr','brand'] + \\\n",
    "        ['tit', 'tit2', 'desc', 'desc2', 'attributes', 'mfgbrand', 'mfgbrand2'] + \\\n",
    "        ['brand_feature'] #['ratio_brand']\n",
    "        #[] #['ratio_title', 'ratio_description', 'ratio_brand']\n",
    "        hd_searches = hd_searches.drop(d_col_drops,axis=1).values\n",
    "        return hd_searches\n",
    "\n",
    "class cust_txt_col(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].apply(str)\n",
    "\n",
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "def fmse(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions)\n",
    "\n",
    "#RMSE  = make_scorer(fmse, greater_is_better=False)\n",
    "RMSE  = make_scorer(fmean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([x for x in \"a,s4\".split(\",\") if x and not re.findall(r'[0-9]', x)])\n",
    "# df_all['query_in_title'] = df_all['tit'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "# df_all['query_in_description'] = df_all['desc'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "# df_all['query_in_attrs'] = df_all['attributes'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "# df_all['query_in_brand'] = df_all['mfgbrand'].map(lambda x: len([x for x in \"\".split(\",\") if x]))\n",
    "if re.match(r'^[0-9]+$', \"srs94343\"):\n",
    "    print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                         (1, [angle], [simpson, strong, tie, 12, gauge, angle])\n",
       "1                                                                                                                             (10, [], [simpson, strong, tie, 12, gauge, angle])\n",
       "2                                                                                (9, [deck], [behr, premium, textured, deck, 1, gal, sc, 141, tugboat, wood, concrete, coating])\n",
       "3                                                                         (9, [shower], [delta, vero, 1, handle, shower, only, faucet, trim, kit, chrome, valve, not, included])\n",
       "4                                                         (9, [shower,  only,  faucet], [delta, vero, 1, handle, shower, only, faucet, trim, kit, chrome, valve, not, included])\n",
       "5                                                                  (6, [convection], [whirlpool, 1, 9, cu, ft, range, convection, microwave, stainless, steel, sensor, cooking])\n",
       "6                                                                   (5, [microwave], [whirlpool, 1, 9, cu, ft, range, convection, microwave, stainless, steel, sensor, cooking])\n",
       "7                                                                   (5, [microwave], [whirlpool, 1, 9, cu, ft, range, convection, microwave, stainless, steel, sensor, cooking])\n",
       "8                                                                        (3, [emergency,  light], [lithonia, lighting, quantum, 2, light, black, led, emergency, fixture, unit])\n",
       "9                                                                                 (3, [mdf,  3,  4], [house, fara, 3, 4, inch, xby, 3, inch, xby, 8, foot, mdf, fluted, casing])\n",
       "10                                                                                                             (3, [stakes], [valley, view, industries, metal, stakes, 4, pack])\n",
       "11        (4, [briggs,  stratton,  lawn,  mower], [toro, personal, pace, recycler, 22, inch, variable, speed, self, propelled, gas, lawn, mower, briggs, amp, stratton, engine])\n",
       "12                             (7, [gas,  mower], [toro, personal, pace, recycler, 22, inch, variable, speed, self, propelled, gas, lawn, mower, briggs, amp, stratton, engine])\n",
       "13                                   (5, [mower], [toro, personal, pace, recycler, 22, inch, variable, speed, self, propelled, gas, lawn, mower, briggs, amp, stratton, engine])\n",
       "14                                                   (14, [bay,  shade,  hampton], [hampton, bay, caramel, simple, weave, bamboo, rollup, shade, 96, inch, w, xby, 72, inch, l])\n",
       "15                                                                                      (1, [disposers], [sinkerator, sink, top, switch, single, outlet, sinkerator, disposers])\n",
       "16                                                              (2, [grill,  gazebo], [sunjoy, calais, 8, foot, xby, 5, foot, xby, 8, foot, steel, tile, fabric, grill, gazebo])\n",
       "17                                                                              (10, [], [md, building, products, 36, inch, xby, 36, inch, cloverleaf, aluminum, sheet, silver])\n",
       "18                                                                              (10, [], [md, building, products, 36, inch, xby, 36, inch, cloverleaf, aluminum, sheet, silver])\n",
       "19                                                                              (10, [], [md, building, products, 36, inch, xby, 36, inch, cloverleaf, aluminum, sheet, silver])\n",
       "20                                                                              (10, [], [md, building, products, 36, inch, xby, 36, inch, cloverleaf, aluminum, sheet, silver])\n",
       "21                                                                                   (10, [], [house, fara, 8, linear, ft, mdf, overlapping, wainscot, interior, paneling, kit])\n",
       "22                                                                        (9, [8,  paneling], [house, fara, 8, linear, ft, mdf, overlapping, wainscot, interior, paneling, kit])\n",
       "23                                                                        (9, [8,  paneling], [house, fara, 8, linear, ft, mdf, overlapping, wainscot, interior, paneling, kit])\n",
       "24                                                                             (6, [mdf,  8], [house, fara, 8, linear, ft, mdf, overlapping, wainscot, interior, paneling, kit])\n",
       "25                                                                            (4, [wainscot], [house, fara, 8, linear, ft, mdf, overlapping, wainscot, interior, paneling, kit])\n",
       "26                                                                 (4, [wainscot,  paneling], [house, fara, 8, linear, ft, mdf, overlapping, wainscot, interior, paneling, kit])\n",
       "27                                                                                                   (10, [], [1804, dual, spray, half, pattern, 4, inch, pop, up, spray, head])\n",
       "28                                                                                                   (10, [], [1804, dual, spray, half, pattern, 4, inch, pop, up, spray, head])\n",
       "29                                                                                       (5, [washer], [samsung, 4, 2, cu, ft, front, load, washer, steam, white, energy, star])\n",
       "                                                                                           ...                                                                                  \n",
       "240730                                                                                                     (4, [panel,  6,  door,  bifold], [6, panel, composite, bifold, door])\n",
       "240731                                                                      (2, [breaker,  amp,  double,  pole,  200], [eaton, csr, 200, amp, double, pole, main, breaker, kit])\n",
       "240732                                                                             (5, [axle,  nuts], [crown, bolt, 3, 16, inch, zinc, plated, steel, axle, hat, nuts, 3, pack])\n",
       "240733                                                                                                               (1, [sheath], [dickies, 2, pocket, utility, knife, sheath])\n",
       "240734                                            (7, [outdoor,  patio,  shade], [patio, living, concepts, san, juan, 60, inch, outdoor, bisque, floor, lamp, sky, blue, shade])\n",
       "240735                                                                                                        (2, [safety,  sign], [speakman, emergency, eyewash, safety, sign])\n",
       "240736                                                                                                        (1, [phone,  cable], [plantronics, cable, m12, cs50, cs55, phone])\n",
       "240737                                                                         (9, [vanguard], [glomar, vanguard, 9, light, textured, black, chandelier, ecru, diamond, shades])\n",
       "240738                                                                                                         (2, [dummy], [kwikset, milan, satin, nickel, half, dummy, lever])\n",
       "240739                                          (15, [advanced,  drainage,  systems], [advanced, drainage, systems, 1, 2, inch, xby, 100, foot, ips, 125, psi, nsf, poly, pipe])\n",
       "240740                                                                                               (7, [led], [magnavox, 50, inch, class, led, 1080, p, 120, bmr, slim, hdtv])\n",
       "240741                                                  (2, [moulding], [ekena, millwork, 7, inch, xby, 3, 4, inch, xby, 11, inch, hillsborough, panel, left, moulding, corner])\n",
       "240742                                                                                 (8, [minwax,  polycrylic], [minwax, 1, gal, semi, gloss, polycrylic, protective, finish])\n",
       "240743                                                                                    (1, [camellia], [southern, living, plant, collection, 3, gal, pink, stella, camellia])\n",
       "240744                                                                                   (1, [black,  gas,  range], [ge, 5, 0, cu, ft, gas, range, self, cleaning, oven, black])\n",
       "240745                                                                                     (3, [submersible], [southwire, 150, foot, 12, 3, cu, w, g, submersible, pump, cable])\n",
       "240746          (14, [series,  generac,  protector], [generac, protector, series, 15000, watt, 120, 240, volt, liquid, cooled, 3, phase, automatic, standby, diesel, generator])\n",
       "240747                                                                                    (6, [tap], [kohler, clearflo, brass, toe, tap, bath, drain, vibrant, brushed, nickel])\n",
       "240748                                                (6, [ceiling,  fan,  light,  fixture], [casablanca, 4, light, maiden, bronze, ceiling, fan, fixture, cased, white, glass])\n",
       "240749                                                                         (5, [peonies], [glidden, premium, 5, gal, hdgr19, fresh, peonies, satin, latex, exterior, paint])\n",
       "240750                                                                                       (1, [paracord], [everbilt, 1, 8, inch, xby, 50, foot, reflective, black, paracord])\n",
       "240751                                               (11, [4,  inch,  bolt,  1,  20,  2], [crown, bolt, 5, 16, inch, 1, 4, inch, 20, xby, 1, 1, 2, inch, alloy, shoulder, bolt])\n",
       "240752                                              (3, [bath,  chair], [universal, tubs, 4, 5, foot, right, drain, wheel, chair, accessible, whirlpool, air, bath, tub, white])\n",
       "240753                                                        (12, [1,  2,  brass], [everbilt, 12, xby, 1, 1, 2, inch, phillips, brass, flat, head, wood, screws, 2, per, pack])\n",
       "240754                          (5, [shower,  doors], [coastal, shower, doors, legend, series, 24, inch, xby, 64, inch, framed, hinged, shower, door, platinum, obscure, glass])\n",
       "240755                       (16, [24,  white,  storage,  cabinet], [stufurhome, norma, 24, inch, w, xby, 16, inch, d, xby, 34, inch, h, linen, storage, floor, cabinet, white])\n",
       "240756       (5, [adirondack,  cushion], [home, decorators, collection, 49, inch, d, alessandro, spiceberry, polyester, montauk, adirondack, bullnose, outdoor, chair, cushion])\n",
       "240757                                                                                (11, [hb], [simpson, strong, tie, hb, 3, 1, 2, xby, 14, inch, top, flange, joist, hanger])\n",
       "240758                           (7, [hex,  socket], [1, 4, inch, 20, tpi, xby, 1, 1, 2, inch, stainless, steel, button, head, internal, hex, socket, cap, screw, 2, per, pack])\n",
       "240759                                                                                                      (6, [4,  inch,  hole,  saw], [bosch, 4, inch, bi, metal, hole, saw])\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_word(r):\n",
    "    title = r['product_title'].split()\n",
    "    ms = r['tit'].split(\",\")\n",
    "    ic = -1\n",
    "    for m in ms:\n",
    "        for i, t in enumerate(title):\n",
    "            if m == t and i > ic:\n",
    "                ic = i\n",
    "    if ic < 0:\n",
    "        ic = 10\n",
    "    else:\n",
    "        ic = len(title) - ic - 1\n",
    "    return ic #, ms, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['desc'].map(lambda y: len([x for x in y.split(\",\") if x and not re.findall(r'[0-9]', x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Features Set: 0.15 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#comment out the lines below use df_all.csv for further grid search testing\n",
    "#if adding features consider any drops on the 'cust_regression_vals' class\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "df_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x: max(1, len(x.split()))).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x: len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['letters_query'] = df_all['search_term'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_title'] = df_all['product_title'].map(lambda x:len(x)).astype(np.int64)\n",
    "df_all['letters_desc'] = df_all['product_description'].map(lambda x:len(x)).astype(np.int64)\n",
    "df_all['letters_brand'] = df_all['brand'].map(lambda x:len(x)).astype(np.int64)\n",
    "\n",
    "###############################\n",
    "# df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\n",
    "# df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))\n",
    "\n",
    "# df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "# df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "# df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "\n",
    "df_all['query_in_title'] = df_all['tit'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_description'] = df_all['desc'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_attrs'] = df_all['attributes'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_brand'] = df_all['mfgbrand'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "\n",
    "df_all['letters_query_in_title'] = df_all['tit'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_description'] = df_all['desc'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_attrs'] = df_all['attributes'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_brand'] = df_all['mfgbrand'].map(lambda x: len(x)).astype(np.int64)\n",
    "\n",
    "\n",
    "df_all['query_in_title2'] = df_all['tit2'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_description2'] = df_all['desc2'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_brand2'] = df_all['mfgbrand2'].map(lambda y: len([x for x in y.split(\",\") if x and not re.match(r'^[0-9]+$', x)]))\n",
    "\n",
    "\n",
    "df_all['letters_query_in_title2'] = df_all['tit2'].map(lambda x: len(x)).astype(np.int64)\n",
    "df_all['letters_query_in_description2'] = df_all['desc2'].map(lambda x: len(x)).astype(np.int64)\n",
    "\n",
    "df_all['ratio_letters_query_in_title'] = df_all['letters_query_in_title2']/(df_all['letters_query_in_title'] + 1)\n",
    "df_all['ratio_letters_query_in_descr'] = df_all['letters_query_in_description2']/(df_all['letters_query_in_description'] + 1)\n",
    "\n",
    "\n",
    "df_all['query_in_title_num'] = df_all['tit'].map(lambda y: len([x for x in y.split(\",\") if x and re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_description_num'] = df_all['desc'].map(lambda y: len([x for x in y.split(\",\") if x and re.match(r'^[0-9]+$', x)]))\n",
    "df_all['query_in_attrs_num'] = df_all['attributes'].map(lambda y: len([x for x in y.split(\",\") if x and re.match(r'^[0-9]+$', x)]))\n",
    "\n",
    "\n",
    "\n",
    "#df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "#df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "#df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "###############################\n",
    "\n",
    "\n",
    "df_all['ratio_title'] = df_all['query_in_title']/df_all['len_of_query']\n",
    "df_all['ratio_description'] = df_all['query_in_description']/df_all['len_of_query']\n",
    "\n",
    "# df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']\n",
    "# df_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']\n",
    "# df_all['ratio_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\n",
    "\n",
    "\n",
    "\n",
    "df_all['title_match_last_word'] = df_all.apply(last_word, axis=1)\n",
    "\n",
    "\n",
    "df_brand = pd.unique(df_all.brand.ravel())\n",
    "d={}\n",
    "i = 1\n",
    "for s in df_brand:\n",
    "    d[s]=i\n",
    "    i+=1\n",
    "df_all['brand_feature'] = df_all['brand'].map(lambda x: d[x])\n",
    "#df_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x))\n",
    "\n",
    "#df_all.to_csv('df_all_322_1.csv')\n",
    "#df_all = pd.read_csv('df_all.csv', encoding=\"ISO-8859-1\", index_col=0)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train[:]\n",
    "X_test = df_test[:]\n",
    "print(\"--- Features Set: %s minutes ---\" % round(((time.time() - start_time)/60), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>tit</th>\n",
       "      <th>tit2</th>\n",
       "      <th>desc</th>\n",
       "      <th>...</th>\n",
       "      <th>letters_query_in_title2</th>\n",
       "      <th>letters_query_in_description2</th>\n",
       "      <th>query_in_title_num</th>\n",
       "      <th>query_in_description_num</th>\n",
       "      <th>query_in_attrs_num</th>\n",
       "      <th>ratio_title</th>\n",
       "      <th>ratio_description</th>\n",
       "      <th>brand_feature</th>\n",
       "      <th>ratio_letters_query_in_title</th>\n",
       "      <th>ratio_letters_query_in_descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>simpson strong tie 12 gauge angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>not only do angles make joints stronger they a...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td>angle</td>\n",
       "      <td></td>\n",
       "      <td>angled, angles</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{u'brand': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>simpson strong tie 12 gauge angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>not only do angles make joints stronger they a...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'brand': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      product_title  product_uid  relevance  \\\n",
       "0   2  simpson strong tie 12 gauge angle       100001        3.0   \n",
       "1   3  simpson strong tie 12 gauge angle       100001        2.5   \n",
       "\n",
       "     search_term                                product_description  \\\n",
       "0  angle bracket  not only do angles make joints stronger they a...   \n",
       "1      l bracket  not only do angles make joints stronger they a...   \n",
       "\n",
       "                brand    tit tit2            desc  \\\n",
       "0  simpson strong tie  angle       angled, angles   \n",
       "1  simpson strong tie                               \n",
       "\n",
       "               ...              letters_query_in_title2  \\\n",
       "0              ...                                    0   \n",
       "1              ...                                    0   \n",
       "\n",
       "  letters_query_in_description2 query_in_title_num query_in_description_num  \\\n",
       "0                             0                  0                        0   \n",
       "1                             0                  0                        0   \n",
       "\n",
       "  query_in_attrs_num ratio_title  ratio_description  brand_feature  \\\n",
       "0                  0         0.5                  1  {u'brand': 1}   \n",
       "1                  0         0.0                  0  {u'brand': 1}   \n",
       "\n",
       "   ratio_letters_query_in_title  ratio_letters_query_in_descr  \n",
       "0                             0                             0  \n",
       "1                             0                             0  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[0:2]\n",
    "#df_all['query_in_title'] + 1\n",
    "#df_all['query_in_title2']/(df_all['query_in_title'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD FROM SAVED\n",
    "#df_all = pd.read_csv('df_all.csv', encoding=\"ISO-8859-1\", index_col=0)\n",
    "#df_all = pd.read_csv('df_all_322_1.csv', encoding=\"ISO-8859-1\", index_col=0)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train[:]\n",
    "X_test = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_all[300:320][['relevance', 'product_title', 'search_term', 'product_description']]\n",
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "#tsvd = TruncatedSVD(n_components=10, random_state = 2016)\n",
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# dictvect = DictVectorizer()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohenc = OneHotEncoder()\n",
    "randomForestRegressor = RandomForestRegressor(n_estimators = 100, min_samples_leaf=3, n_jobs = -1, random_state = 5017, verbose = 1)\n",
    "\n",
    "clf = pipeline.Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                    transformer_list = [\n",
    "                        ('cst',  cust_regression_vals()),  \n",
    "                    \n",
    "#                         ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n",
    "#                         ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])),\n",
    "#                         ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n",
    "#                         ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))\n",
    "                    \n",
    "#                         ('txt1', pipeline.Pipeline([ ('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf)  ])),\n",
    "#                         ('txt2', pipeline.Pipeline([ ('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf)  ])),\n",
    "#                         ('txt3', pipeline.Pipeline([ ('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf) ])),\n",
    "#                         ('txt4', pipeline.Pipeline([ ('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf) ]))\n",
    "                    \n",
    "#                         ('brandf', pipeline.Pipeline([ ('s5', cust_txt_col(key='brand_feature')), ('ohenc', ohenc)  ])),\n",
    "                        ],\n",
    "                    transformer_weights = {\n",
    "                        'cst': 1.0,\n",
    "#                         'txt1': 0.5,\n",
    "#                         'txt2': 0.25,\n",
    "#                         'txt3': 0.5,\n",
    "#                         'txt4': 0.5\n",
    "#                         'brandf': 1.0\n",
    "                        },\n",
    "                n_jobs = -1\n",
    "                )), \n",
    "        ('rfr', randomForestRegressor)])\n",
    "\n",
    "#clf.set_params(rfr__max_features=10, rfr__max_depth=20)\n",
    "#clf.fit(X_train, y_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   3 | elapsed:    4.9s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.5s finished\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:449: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:449: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:449: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of 100 | elapsed:    0.1s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of  24 | elapsed:    0.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of 100 | elapsed:    0.1s remaining:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:475: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:475: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Library/Python/2.7/site-packages/sklearn/pipeline.py:475: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "[Parallel(n_jobs=8)]: Done   1 out of 100 | elapsed:    0.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done   1 out of 100 | elapsed:    0.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done   1 out of 100 | elapsed:    0.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] rfr__max_features=2, rfr__max_depth=30 ..........................\n",
      "[CV] rfr__max_features=2, rfr__max_depth=30 ..........................\n",
      "[CV] rfr__max_features=2, rfr__max_depth=30 ..........................\n",
      "[CV]  rfr__max_features=2, rfr__max_depth=30, score=-0.477268 -   1.4s[CV]  rfr__max_features=2, rfr__max_depth=30, score=-0.465405 -   1.3s[CV]  rfr__max_features=2, rfr__max_depth=30, score=-0.494196 -   1.1s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of 100 | elapsed:    0.1s remaining:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training: 0.17 minutes ---\n",
      "Best parameters found by grid search:\n",
      "{'rfr__max_features': 2, 'rfr__max_depth': 30}\n",
      "Best CV score:\n",
      "-0.478956196878\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = {'rfr__max_features': [2], 'rfr__max_depth': [30]}\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 3, verbose = 20, scoring=RMSE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- Training: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train.ix[3782]\n",
    "inds = pd.isnull(X_train).any(1).nonzero()[0]\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isfinite(X_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isfinite(X_train).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'rfr__max_features': 2, 'rfr__max_depth': 30}\n",
      "Best CV score:\n",
      "-0.471630661431\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'rfr__max_features': 2, 'rfr__max_depth': 30}\n",
      "Best CV score:\n",
      "-0.471630661431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of 500 | elapsed:    0.0s remaining:   24.2s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
