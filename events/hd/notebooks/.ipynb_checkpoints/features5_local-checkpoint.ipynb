{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn import pipeline, model_selection\n",
    "from sklearn import pipeline, grid_search\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "random.seed(2016)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "# LOC = '/home/ec2-user/data/hd/unpacked/'\n",
    "# df_train = pd.read_csv(LOC + 'train.csv', encoding=\"ISO-8859-1\")\n",
    "# num_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(\"train.buffer\")\n",
    "dtest = xgb.DMatrix(\"test.buffer\")\n",
    "evallist  = [(dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = '%s'\n",
    "#loc = '/home/ec2-user/data/hd/features/%s'\n",
    "a_o = np.load(loc % 'train_data.npy')\n",
    "b_o = np.load(loc % 'test_data.npy')\n",
    "a_brand = np.load(loc % 'features_brand_01_train.npy')\n",
    "b_brand = np.load(loc % 'features_brand_01_test.npy')\n",
    "a_other = np.load(loc % 'FEATURES_1d_TRAIN.npy')\n",
    "b_other = np.load(loc % 'FEATURES_1d_TEST.npy')\n",
    "a_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TRAIN.npy')\n",
    "b_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TEST.npy')\n",
    "\n",
    "\n",
    "# a_word_cooc = np.load(loc % 'WORD_COOCCUR_FEATURES_TRAIN.npy')\n",
    "# b_word_cooc = np.load(loc % 'WORD_COOCCUR_FEATURES_TEST.npy')\n",
    "# #leak:\n",
    "# a_word_cooc = a_word_cooc[:,[0,3]]\n",
    "# b_word_cooc = b_word_cooc[:,[0,3]]\n",
    "\n",
    "\n",
    "aaa = pd.read_pickle(loc % 'WOQTAL_TRAIN_147')\n",
    "bbb = pd.read_pickle(loc % 'WOQTAL_TEST_147')\n",
    "aa = aaa.drop('relevance', axis=1).values #[:,[0,3]]\n",
    "bb = bbb.drop('relevance', axis=1).values #[:,[0,3]]\n",
    "\n",
    "\n",
    "a = np.hstack((a_o, a_brand, a_other, a_word_feat, aa))\n",
    "b = np.hstack((b_o, b_brand, b_other, b_word_feat, bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01995863,  0.04264898,  0.00459666,  0.00886746,  0.02096461,\n",
       "         0.00226756],\n",
       "       [ 0.01797451,  0.05845031,  0.00203976,  0.01973299,  0.06321615,\n",
       "         0.00188688],\n",
       "       [ 0.12325276,  0.24122003,  0.02828339,  0.03641738,  0.10727625,\n",
       "         0.01241042],\n",
       "       ..., \n",
       "       [ 0.03556485,  0.05014563,  0.        ,  0.03769401,  0.0853719 ,\n",
       "         0.        ],\n",
       "       [ 0.17889046,  0.38284767,  0.01641287,  0.03508537,  0.07529128,\n",
       "         0.00583763],\n",
       "       [ 0.10337516,  0.27305618,  0.01532494,  0.09322681,  0.28443367,\n",
       "         0.02028718]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FINAL GENERATE\n",
    "aaa = pd.read_pickle(loc % 'WOQTAL_TRAIN_ALL')\n",
    "bbb = pd.read_pickle(loc % 'WOQTAL_TEST_ALL')\n",
    "aa = aaa.drop('relevance', axis=1).values[:,[0,3]]\n",
    "bb = bbb.drop('relevance', axis=1).values[:,[0,3]]\n",
    "\n",
    "\n",
    "a = np.hstack((a_o, a_brand, a_other, a_word_feat, aa))\n",
    "b = np.hstack((b_o, b_brand, b_other, b_word_feat, bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,r in enumerate(a_word_feat):\n",
    "    if np.any(np.isnan(r)):\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a, dtrain.get_label(), test_size=0.20, random_state=147) # 0.20, 147\n",
    "gX_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "gX_test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "evallist  = [(gX_train,'train'),(gX_test,'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46102766153075159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = linear_model.LinearRegression(n_jobs=8)\n",
    "clf = linear_model.Ridge (alpha = .6)\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "y_hat = np.minimum(np.maximum(y_hat, 1.0), 3.0)\n",
    "fmean_squared_error(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN AS SELF\n",
    "param = {'max_depth':9, \n",
    "         'eta':0.1, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.3,\n",
    "         'subsample':0.9,\n",
    "         'nthread':8,\n",
    "         'silent': True\n",
    "        }\n",
    "# GOOD\n",
    "param = {'max_depth':10, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.8, #7\n",
    "         'subsample':0.9,  #8\n",
    "         'min_child_weight': 10.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }\n",
    "\n",
    "def next_num_round():\n",
    "    return np.random.randint(750, 950)\n",
    "\n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=15, verbose_eval=10)\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 700x trees  -  cv: 0.4377 (seed 147)\n",
    "param = {'max_depth':9, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.6, #0.8 #7  0.4449\n",
    "         'subsample':0.8, #0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }  \n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=15, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ggX_train = xgb.DMatrix(data=a, label=dtrain.get_label())\n",
    "num_round = 900\n",
    "bst = xgb.train( param, ggX_train, num_round, [(gX_test,'test')], verbose_eval=10)\n",
    "\n",
    "idx_train = pd.read_pickle(loc % 'LABELS_TRAIN.df')\n",
    "idx_test = pd.read_pickle(loc % 'LABELS_TEST.df')\n",
    "\n",
    "ggX_test = xgb.DMatrix(data=b)\n",
    "y_pred = bst.predict(ggX_test)\n",
    "y_pred_bounded = np.minimum(np.maximum(y_pred, 1.0), 3.0)\n",
    "idx_test['relevance'] = y_pred_bounded\n",
    "idx_test.to_csv('submission_xgboost_words_0405_1646.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gzip submission_xgboost_words_0405_1646.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1500 trees \n",
    "param = {'max_depth':9, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.8, #0.8 #7  0.4449\n",
    "         'subsample':0.9, #0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }  \n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=15, verbose_eval=10)\n",
    "\n",
    "with 0.30 and 1479\n",
    "cv:  0.4493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
