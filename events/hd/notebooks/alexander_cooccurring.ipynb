{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn import pipeline, model_selection\n",
    "from sklearn import pipeline, grid_search\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "random.seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = '/home/ec2-user/data/hd/features/%s'\n",
    "\n",
    "queries = pd.read_pickle(loc % 'FEATURES_WITH_TEXT_1.data')\n",
    "\n",
    "idx_train = pd.read_pickle(loc % 'LABELS_TRAIN.df')\n",
    "idx_test = pd.read_pickle(loc % 'LABELS_TEST.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53907,), (20160,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_idx = pd.read_csv(loc % 'valid_set.csv', index_col= 'id').index\n",
    "train_idx = idx_train.index.difference(validation_idx)\n",
    "\n",
    "train_idx.shape, validation_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IDX_TR, IDX_TE = train_test_split(idx_train.index, test_size=0.20, random_state=117)\n",
    "IDX_TR, IDX_TE = np.array(train_idx), np.array(validation_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDX_TRAIN = idx_train.loc[IDX_TR]\n",
    "\n",
    "IDX_TEST = idx_train.loc[IDX_TE]\n",
    "IDX_TEST['orig_rel'] = IDX_TEST['relevance']\n",
    "IDX_TEST['relevance'] = -1\n",
    "\n",
    "idx_test['relevance'] = -1\n",
    "\n",
    "known_labels = pd.concat([IDX_TRAIN, IDX_TEST, idx_test]).join(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.00    186853\n",
       " 3.00     15129\n",
       " 2.33     11382\n",
       " 2.67     11140\n",
       " 2.00      8053\n",
       " 1.67      4659\n",
       " 1.33      2042\n",
       " 1.00      1459\n",
       " 2.50        11\n",
       " 2.75         9\n",
       " 1.75         8\n",
       " 2.25         7\n",
       " 1.50         5\n",
       " 1.25         3\n",
       "Name: relevance, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_labels.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_digit = re.compile('([0-9]|units|xby)')\n",
    "\n",
    "def calculate_word_pairs(a1, a2):\n",
    "    \n",
    "    word_matches = defaultdict(lambda : defaultdict(lambda : defaultdict(lambda: 0)))\n",
    "    word_matches_score_raw = defaultdict(lambda : defaultdict(lambda : defaultdict(lambda: 0)))\n",
    "    word_matches_score_offset = defaultdict(lambda : defaultdict(lambda : defaultdict(lambda: 0)))\n",
    "    word_counts = defaultdict(lambda : defaultdict(lambda : 0))\n",
    "    word_counts_score = defaultdict(lambda : defaultdict(lambda : 0))\n",
    "    \n",
    "    def f(r):\n",
    "        ID = r['id']\n",
    "        query = r[a1]\n",
    "        if not query:\n",
    "            query = \"NOWORDS\"\n",
    "        qs = [q for q in query.split() if not has_digit.search(q)]\n",
    "\n",
    "        title = r[a2]\n",
    "        if not title:\n",
    "            title = \"NOWORDS\"\n",
    "        ts = [t for t in title.split() if not has_digit.search(t)]\n",
    "\n",
    "        score = r['relevance']\n",
    "        for q in qs:\n",
    "            c = 0\n",
    "            c_score = 0\n",
    "            for t in ts:\n",
    "                word_matches[ID][q][t] += 1\n",
    "                if score > 0:\n",
    "                    word_matches_score_raw[ID][q][t] += score\n",
    "                    word_matches_score_offset[ID][q][t] += (score - 2.38)\n",
    "                    c_score += 1\n",
    "                c += 1\n",
    "            word_counts[ID][q] += c\n",
    "            word_counts_score[ID][q] += c_score\n",
    "    _ = known_labels.reset_index().apply(f, axis=1)\n",
    "    \n",
    "    return (word_matches, word_matches_score_raw, word_matches_score_offset, word_counts, word_counts_score)\n",
    "    \n",
    "word_matches, word_matches_score_raw, word_matches_score_offset, word_counts, word_counts_score = calculate_word_pairs('query', 'product_title')\n",
    "word_matches2, word_matches_score_raw2, word_matches_score_offset2, word_counts2, word_counts_score2 = calculate_word_pairs('product_title', 'query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_dict(given_word_matches):\n",
    "    total_wm = defaultdict(lambda : defaultdict(lambda: 0))\n",
    "    for ID, wm in given_word_matches.items():\n",
    "        for q, tc in wm.items():\n",
    "            for t, c in tc.items():\n",
    "                total_wm[q][t] += c\n",
    "    total_wm = { q: { t: c for t,c in tc.items() } for q,tc in total_wm.items()}\n",
    "    return total_wm\n",
    "\n",
    "def get_train_counts(given_word_count):\n",
    "    total_wc = defaultdict(lambda : 0)\n",
    "    for ID, wm in given_word_count.items():\n",
    "        for q, c in wm.items():\n",
    "            total_wc[q] += c\n",
    "    total_wc = { t: c for t,c in total_wc.items()}\n",
    "    return total_wc\n",
    "\n",
    "train_word_matches = get_train_dict(word_matches)\n",
    "train_word_matches_score_raw = get_train_dict(word_matches_score_raw)\n",
    "train_word_matches_score_offset = get_train_dict(word_matches_score_offset)\n",
    "train_word_counts = get_train_counts(word_counts)\n",
    "train_word_counts_score = get_train_counts(word_counts_score)\n",
    "\n",
    "train_word_matches2 = get_train_dict(word_matches2)\n",
    "train_word_matches_score_raw2 = get_train_dict(word_matches_score_raw2)\n",
    "train_word_matches_score_offset2 = get_train_dict(word_matches_score_offset2)\n",
    "train_word_counts2 = get_train_counts(word_counts2)\n",
    "train_word_counts_score2 = get_train_counts(word_counts_score2)\n",
    "\n",
    "\n",
    "#sorted([(v, k) for k,v in train_word_matches_score_offset['pt'].items()], reverse=True)[0:12], \n",
    "#sorted([(v, k) for k,v in train_word_matches_score_offset2['showerhead'].items()], reverse=True)[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trimmed_dict(zad, d, zawc, wc, no_id, qs):\n",
    "    \n",
    "    #ad = { q: v.copy() for q, v in zad.items() }\n",
    "    ad = {}\n",
    "    awc = zawc.copy()\n",
    "        \n",
    "    ded = d.get(no_id, None)\n",
    "    dewc = wc.get(no_id, None)\n",
    "    \n",
    "    for q in qs:\n",
    "        adq = zad.get(q, None)\n",
    "        if adq:\n",
    "            ad[q] = zad[q].copy()\n",
    "        else:\n",
    "            ad[q] = {}\n",
    "        \n",
    "    if ded:\n",
    "        for q, tc in ded.items():  \n",
    "            for t, c in tc.items():\n",
    "                ad[q][t] -= c\n",
    "            awc[q] -= dewc[q]\n",
    "            \n",
    "    for q, tc in ad.items():\n",
    "        for t, c in ad[q].items():\n",
    "            denom = awc.get(q, 0) + 1.0\n",
    "            a = ad[q][t]\n",
    "            if a < 0.0000001:\n",
    "                del ad[q][t]\n",
    "            else:\n",
    "                ad[q][t] = a*1.0/denom\n",
    "        if not ad[q]:\n",
    "            del ad[q]\n",
    "    return ad\n",
    "\n",
    "def get_features_no_id(r):\n",
    "    ID = r['id']\n",
    "    \n",
    "    query = r['query']\n",
    "    if not query:\n",
    "        query = \"NOWORDS\"\n",
    "    qs = [q for q in query.split() if not has_digit.search(q)]\n",
    "\n",
    "    title = r['product_title']\n",
    "    if not title:\n",
    "        title = \"NOWORDS\"\n",
    "    ts = [t for t in title.split() if not has_digit.search(t)]\n",
    "\n",
    "    myd1 = trimmed_dict(train_word_matches, word_matches, train_word_counts, word_counts, ID, qs)\n",
    "    myd2 = trimmed_dict(train_word_matches_score_raw, word_matches_score_raw, train_word_counts_score, word_counts_score, ID, qs)\n",
    "    myd3 = trimmed_dict(train_word_matches_score_offset, word_matches_score_offset, train_word_counts_score, word_counts_score, ID, qs)\n",
    "    myd4 = trimmed_dict(train_word_matches2, word_matches2, train_word_counts2, word_counts2, ID, ts)\n",
    "    myd5 = trimmed_dict(train_word_matches_score_raw2, word_matches_score_raw2, train_word_counts_score2, word_counts_score2, ID, ts)\n",
    "    myd6 = trimmed_dict(train_word_matches_score_offset2, word_matches_score_offset2, train_word_counts_score2, word_counts_score2, ID, ts)\n",
    "    \n",
    "\n",
    "\n",
    "    a1, a2, a3 = 0.0, 0.0, 0.0\n",
    "    b1, b2, b3 = 0.0, 0.0, 0.0\n",
    "    for q in qs:\n",
    "        qt1 = myd1.get(q, None)\n",
    "        qt2 = myd2.get(q, None)\n",
    "        qt3 = myd3.get(q, None)\n",
    "        for t in ts:\n",
    "            if qt1:\n",
    "                a1 += qt1.get(t, 0)\n",
    "            if qt2:\n",
    "                a2 += qt2.get(t, 0)\n",
    "            if qt3:\n",
    "                a3 += qt3.get(t, 0)\n",
    "    for t in ts:\n",
    "        tq1 = myd4.get(t, None)\n",
    "        tq2 = myd5.get(t, None)\n",
    "        tq3 = myd6.get(t, None)\n",
    "        for q in qs:\n",
    "            if tq1:\n",
    "                b1 += tq1.get(q, 0)\n",
    "            if tq2:\n",
    "                b2 += tq2.get(q, 0)\n",
    "            if tq3:\n",
    "                b3 += tq3.get(q, 0)\n",
    "    a1 /= (len(qs) + 1)\n",
    "    a2 /= (len(qs) + 1)\n",
    "    a3 /= (len(qs) + 1)\n",
    "    b1 /= (len(ts) + 1)\n",
    "    b2 /= (len(ts) + 1)\n",
    "    b3 /= (len(ts) + 1)        \n",
    "    return pd.Series([ID, a1, a2, a3, b1, b2, b3])\n",
    "\n",
    "#myd1 = trimmed_dict(train_word_matches, word_matches, train_word_counts, word_counts, 214616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "woqta = known_labels.reset_index().apply(get_features_no_id, axis=1)\n",
    "woqta.columns = ['id', 'woqt1', 'woqt2', 'woqt3', 'woqt4', 'woqt5', 'woqt6']\n",
    "woqta['id'] = woqta['id'].astype(int)\n",
    "woqta.set_index('id', inplace=True)\n",
    "\n",
    "WOQTA_TRAIN = idx_train.join(woqta)\n",
    "WOQTA_TEST = idx_test.join(woqta)\n",
    "\n",
    "WOQTA_TRAIN.to_pickle('WOQTAL_TRAIN_ALEX')\n",
    "WOQTA_TEST.to_pickle('WOQTAL_TEST_ALEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WOQTA_TRAIN = IDX_TRAIN.join(woqta).reset_index()\n",
    "WOQTA_TRAIN.to_csv('word_co_train_local.csv', index=False)\n",
    "\n",
    "WOQTA_TEST = IDX_TEST.drop('relevance', axis=1).join(woqta).reset_index()\n",
    "WOQTA_TEST.to_csv('word_co_validate_local.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#started around 14:50\n",
    "# finished ~16:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>orig_rel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221398</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221400</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221401</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221404</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221405</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221407</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221408</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221409</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221411</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221412</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221413</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221415</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221416</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221419</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221420</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221422</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221423</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221426</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221427</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221432</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221434</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221443</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221449</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221450</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221455</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221457</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221458</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221463</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221471</th>\n",
       "      <td>-1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221473</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20160 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        relevance  orig_rel\n",
       "id                         \n",
       "2              -1      3.00\n",
       "16             -1      2.33\n",
       "18             -1      3.00\n",
       "35             -1      3.00\n",
       "69             -1      1.00\n",
       "88             -1      1.33\n",
       "113            -1      2.00\n",
       "117            -1      2.67\n",
       "123            -1      3.00\n",
       "136            -1      2.00\n",
       "147            -1      2.00\n",
       "164            -1      1.67\n",
       "172            -1      3.00\n",
       "201            -1      2.33\n",
       "214            -1      2.33\n",
       "223            -1      2.33\n",
       "241            -1      3.00\n",
       "257            -1      2.00\n",
       "272            -1      3.00\n",
       "293            -1      3.00\n",
       "314            -1      3.00\n",
       "323            -1      2.33\n",
       "341            -1      2.33\n",
       "351            -1      3.00\n",
       "361            -1      2.33\n",
       "373            -1      2.00\n",
       "389            -1      2.33\n",
       "440            -1      2.33\n",
       "468            -1      3.00\n",
       "475            -1      2.33\n",
       "...           ...       ...\n",
       "221398         -1      1.67\n",
       "221400         -1      1.33\n",
       "221401         -1      2.33\n",
       "221404         -1      2.33\n",
       "221405         -1      2.67\n",
       "221407         -1      1.67\n",
       "221408         -1      3.00\n",
       "221409         -1      2.67\n",
       "221411         -1      1.33\n",
       "221412         -1      2.00\n",
       "221413         -1      1.67\n",
       "221415         -1      2.00\n",
       "221416         -1      1.00\n",
       "221419         -1      2.33\n",
       "221420         -1      2.00\n",
       "221422         -1      2.33\n",
       "221423         -1      2.33\n",
       "221426         -1      2.00\n",
       "221427         -1      1.67\n",
       "221432         -1      2.00\n",
       "221434         -1      2.67\n",
       "221443         -1      3.00\n",
       "221449         -1      3.00\n",
       "221450         -1      2.00\n",
       "221455         -1      3.00\n",
       "221457         -1      1.00\n",
       "221458         -1      3.00\n",
       "221463         -1      2.33\n",
       "221471         -1      3.00\n",
       "221473         -1      2.33\n",
       "\n",
       "[20160 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDX_TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
