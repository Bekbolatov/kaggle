{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cum4\n",
    "params = [\n",
    "    {'max_depth':9, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.6, #7\n",
    "     'subsample':0.8,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    },\n",
    "    {'max_depth':8, \n",
    "     'eta':0.02, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.3, #7\n",
    "     'subsample':0.8,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    },\n",
    "    {'max_depth':10, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.6, #7\n",
    "     'subsample':0.8,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    },\n",
    "    {'max_depth':8, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.5, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 6.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    }\n",
    "]\n",
    "num_rounds = [1000, 580, 680, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn import pipeline, model_selection\n",
    "from sklearn import pipeline, grid_search\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "random.seed(2016)\n",
    "\n",
    "dtrain = xgb.DMatrix(\"train.buffer\")\n",
    "dtest = xgb.DMatrix(\"test.buffer\")\n",
    "evallist  = [(dtrain,'train')]\n",
    "\n",
    "\n",
    "loc = '/home/ec2-user/data/hd/features/%s'\n",
    "a_o = np.load(loc % 'train_data.npy')\n",
    "b_o = np.load(loc % 'test_data.npy')\n",
    "a_brand = np.load(loc % 'features_brand_01_train.npy')\n",
    "b_brand = np.load(loc % 'features_brand_01_test.npy')\n",
    "a_other = np.load(loc % 'FEATURES_1d_TRAIN.npy')\n",
    "b_other = np.load(loc % 'FEATURES_1d_TEST.npy')\n",
    "a_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TRAIN.npy')\n",
    "b_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TEST.npy')\n",
    "#FINAL GENERATE\n",
    "aaa = pd.read_pickle(loc % 'WOQTAL_TRAIN_ALL')\n",
    "bbb = pd.read_pickle(loc % 'WOQTAL_TEST_ALL')\n",
    "aa = aaa.drop('relevance', axis=1).values[:,[0,3]]\n",
    "bb = bbb.drop('relevance', axis=1).values[:,[0,3]]\n",
    "\n",
    "a = np.hstack((a_o, a_brand, a_other, a_word_feat, aa))\n",
    "b = np.hstack((b_o, b_brand, b_other, b_word_feat, bb))\n",
    "\n",
    "ggX_train = xgb.DMatrix(data=a, label=dtrain.get_label())\n",
    "ggX_test = xgb.DMatrix(data=b)\n",
    "idx_train = pd.read_pickle(loc % 'LABELS_TRAIN.df')\n",
    "idx_test = pd.read_pickle(loc % 'LABELS_TEST.df')\n",
    "\n",
    "\n",
    "params = [\n",
    "    {'max_depth':9, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.7, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    },\n",
    "    {'max_depth':7, \n",
    "     'eta':0.03, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.7, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    },\n",
    "    {'max_depth':7, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.7, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    },\n",
    "    {'max_depth':8, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.7, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 6.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    }\n",
    "]\n",
    "num_rounds = [1000, 450, 700, 1000]\n",
    "\n",
    "def next_param():\n",
    "    return np.random.randint(0,len(params))\n",
    "\n",
    "running_total = pd.DataFrame({'A' : []})\n",
    "for i in range(20000):\n",
    "    print (\"Starting run: %d\" % i)\n",
    "    \n",
    "    r = next_param() \n",
    "    param = params[r]\n",
    "    param['seed'] = i*137 + 110\n",
    "    num_round = num_rounds[r]\n",
    "    print (\"Num rounds: %d\" % num_round)\n",
    "    \n",
    "    bst = xgb.train( param, ggX_train, num_round, [(gX_test,'test')], verbose_eval=200)\n",
    "    y_pred = bst.predict(ggX_test)    \n",
    "    y_pred_bounded = np.minimum(np.maximum(y_pred, 1.0), 3.0)\n",
    "    idx_test['relevance'] = y_pred_bounded\n",
    "    idx_test.to_csv('submission_xgboost_many5_%05d.csv' % i)\n",
    "    \n",
    "    if not running_total.empty:\n",
    "        running_total = running_total + idx_test\n",
    "    else:\n",
    "        running_total = idx_test\n",
    "        \n",
    "    y_pred_bounded = np.minimum(np.maximum(running_total['relevance']/(i+1), 1.0), 3.0)\n",
    "    idx_test['relevance'] = y_pred_bounded\n",
    "    idx_test.to_csv('submission_xgboost_cum5_%05d.csv' % i)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(750, 950)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
