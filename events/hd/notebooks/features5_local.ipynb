{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import random\n",
    "random.seed(2016)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import pipeline, grid_search\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(\"train.buffer\")\n",
    "dtest = xgb.DMatrix(\"test.buffer\")\n",
    "evallist  = [(dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = '%s'\n",
    "#loc = '/home/ec2-user/data/hd/features/%s'\n",
    "a_o = np.load(loc % 'train_data.npy')\n",
    "b_o = np.load(loc % 'test_data.npy')\n",
    "a_brand = np.load(loc % 'features_brand_01_train.npy')\n",
    "b_brand = np.load(loc % 'features_brand_01_test.npy')\n",
    "a_other = np.load(loc % 'FEATURES_1d_TRAIN.npy')\n",
    "b_other = np.load(loc % 'FEATURES_1d_TEST.npy')\n",
    "a_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TRAIN.npy')\n",
    "b_word_feat = np.load(loc % 'SPECIAL_WORDS_FEAT_TEST.npy')\n",
    "\n",
    "a_w2vdot = pd.read_pickle(loc % 'W2V_dots_train.df').drop('relevance', axis=1).values\n",
    "b_w2vdot = pd.read_pickle(loc % 'W2V_dots_test.df').drop('relevance', axis=1).values\n",
    "\n",
    "a_w2vdist = np.load(loc % 'W2V_dists_train.npz')['arr_0']\n",
    "b_w2vdist = np.load(loc % 'W2V_dists_test.npz')['arr_0']\n",
    "\n",
    "a_w2v_el = np.load(loc % 'W2V_vecs_train.npz')['arr_0']\n",
    "b_w2v_el = np.load(loc % 'W2V_vecs_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOCAL CV\n",
    "aaa = pd.read_pickle(loc % 'WOQTAL_TRAIN_147')\n",
    "bbb = pd.read_pickle(loc % 'WOQTAL_TEST_147')\n",
    "aa = aaa.drop('relevance', axis=1).values\n",
    "bb = bbb.drop('relevance', axis=1).values\n",
    "#aa = aaa.drop('relevance', axis=1).values #[:,[0,3]]\n",
    "#bb = bbb.drop('relevance', axis=1).values #[:,[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = np.hstack((a_o, a_brand, a_other, a_word_feat, aa, a_w2vdot, a_w2vdist, a_w2v_el))\n",
    "#b = np.hstack((b_o, b_brand, b_other, b_word_feat, bb, b_w2vdot, b_w2vdist, b_w2v_el))\n",
    "a = np.hstack((a_o, a_brand, a_other, a_word_feat, aa, a_w2vdot, a_w2vdist, a_w2v_el[:,:700]))\n",
    "b = np.hstack((b_o, b_brand, b_other, b_word_feat, bb, b_w2vdot, b_w2vdist, b_w2v_el[:,:700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FINAL GENERATE\n",
    "aaa = pd.read_pickle(loc % 'WOQTAL_TRAIN_ALL')\n",
    "bbb = pd.read_pickle(loc % 'WOQTAL_TEST_ALL')\n",
    "aa = aaa.drop('relevance', axis=1).values\n",
    "bb = bbb.drop('relevance', axis=1).values\n",
    "\n",
    "a_full = np.hstack((a_o, a_brand, a_other, a_word_feat, aa, a_w2vdot, a_w2vdist, a_w2v_el))\n",
    "b_full = np.hstack((b_o, b_brand, b_other, b_word_feat, bb, b_w2vdot, b_w2vdist, b_w2v_el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SETS READY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a, dtrain.get_label(), test_size=0.20, random_state=147) # 0.20, 147\n",
    "gX_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "gX_test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "evallist  = [(gX_train,'train'),(gX_test,'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = linear_model.LinearRegression(n_jobs=8)\n",
    "#clf = linear_model.Lasso(alpha=0.01)\n",
    "clf = linear_model.Ridge (alpha = 0.6)\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "y_hat = np.minimum(np.maximum(y_hat, 1.0), 3.0)\n",
    "fmean_squared_error(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checked LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_num_round():\n",
    "    return np.random.randint(750, 950)\n",
    "\n",
    "num_round = 5000\n",
    "\n",
    "# TRAIN AS SELF\n",
    "param = {'max_depth':9, \n",
    "         'eta':0.1, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.3,\n",
    "         'subsample':0.9,\n",
    "         'nthread':8,\n",
    "         'silent': True\n",
    "        }\n",
    "# GOOD <<\n",
    "param = {'max_depth':7, \n",
    "         'eta':0.03, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.7, #7\n",
    "         'subsample':0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }\n",
    "param = {'max_depth':9, \n",
    "     'eta':0.01, # 'objective':'reg:linear',\n",
    "     'eval_metric':'rmse', #'maximize': False,\n",
    "     'colsample_bytree':0.7, #7\n",
    "     'subsample':0.9,  #8\n",
    "     'min_child_weight': 4.0,\n",
    "     'nthread':32,\n",
    "     'silent': True\n",
    "    }\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=15, verbose_eval=10)\n",
    "#bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 700x trees  -  cv: 0.4377 (seed 147)\n",
    "param = {'max_depth':9, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.3, #0.8 #7  0.4449\n",
    "         'subsample':0.8, #0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }  \n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=30, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ggX_train = xgb.DMatrix(data=a_full, label=dtrain.get_label())\n",
    "ggX_test = xgb.DMatrix(data=b_full)\n",
    "\n",
    "num_round = 1000\n",
    "bst = xgb.train( param, ggX_train, num_round, [(gX_test,'test')], verbose_eval=50)\n",
    "\n",
    "idx_train = pd.read_pickle(loc % 'LABELS_TRAIN.df')\n",
    "idx_test = pd.read_pickle(loc % 'LABELS_TEST.df')\n",
    "\n",
    "y_pred = bst.predict(ggX_test)\n",
    "y_pred_bounded = np.minimum(np.maximum(y_pred, 1.0), 3.0)\n",
    "idx_test['relevance'] = y_pred_bounded\n",
    "idx_test.to_csv('submission_xgboost_words_0406_1720.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gzip submission_xgboost_words_0405_1646.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1500 trees \n",
    "param = {'max_depth':9, \n",
    "         'eta':0.01, # 'objective':'reg:linear',\n",
    "         'eval_metric':'rmse', #'maximize': False,\n",
    "         'colsample_bytree':0.8, #0.8 #7  0.4449\n",
    "         'subsample':0.9, #0.9,  #8\n",
    "         'min_child_weight': 4.0,\n",
    "         'nthread':32,\n",
    "         'silent': True\n",
    "        }  \n",
    "num_round = 5000\n",
    "bst = xgb.train( param, gX_train, num_round, [(gX_train,'train'),(gX_test,'test')], early_stopping_rounds=15, verbose_eval=10)\n",
    "\n",
    "with 0.30 and 1479\n",
    "cv:  0.4493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
